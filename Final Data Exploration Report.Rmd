---
title: "Final Data Exploration Report"
author: "Laura Pelayo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(aod)
library(readr)
library(corrplot)
library(ggplot2)
library(tidyverse)
library(sf)
library(dplyr)
library(mapview)
library(viridis)
library(scales)
library(plotly)
library(tmap)
library(leaflet)
library(car) 
library(randomForest)
library(caret)
library(spdep)
library(splm)
library(nnet)
library(spatialreg)
library(fpc)
library(GWmodel)
```

1. Introduction to your problem statement including links to data sources (5 pts)

The objective of this study is to conduct a comprehensive analysis that delves into the relationship between housing and equity. Ideally, Clark County should be envisioned as a place where residents have access to affordable housing.

My data comes from the US department of urban housing and development (HUD), Bureau of Economic Analysis (BEA), U.S. Census Bureau’s, and Clark County, Washington Open Data

HUD Data:
Fair Market Rents (FMRs) for Fiscal Year 2000-2024: https://www.huduser.gov/portal/datasets/fmr.html#year2024
Small Area Fair Market Rents (SAFMRs) for Fiscal Year 2010-2024:https://www.huduser.gov/portal/datasets/fmr/smallarea/index.html#query_2024

BEA Data:
Personal Income: https://apps.bea.gov/iTable/?reqid=70&step=1&acrdn=6

Census Data:
SNAP in the Past 12 Months by Poverty Status in the Past 12 Months for Households: https://censusreporter.org/tables/B22003/
Vacancy Status: https://censusreporter.org/tables/B25004/
Hispanic or Latino Origin by Race: https://censusreporter.org/tables/B03002/
Median Household Income: https://censusreporter.org/tables/B19013/
Educational Attainment: https://censusreporter.org/tables/C15003/
Employment Status: https://censusreporter.org/tables/B23025/

Clark County, WA Open Data: 
Shapefile: https://hub-clarkcountywa.opendata.arcgis.com/pages/digital-gis-data-download

2. Overview of data engineering efforts (10 pts)

Below is a detailed description of my data engineering efforts. 

The first data I worked with was Fair Market Rents (FMRs) in MSA and (SAFMRs) in Clark County.

Data Loading:
df_msa: Fair Market Rents (FMRs) data for the Portland-Vancouver-Hillsboro region for the fiscal years 2000-2024 is loaded from the FMRs By FY.csv file.
df_clark: Fair Market Rents (FMRs) data specifically for Clark County for the fiscal years 2011-2024 is loaded from the FY Small Area FMRs.csv file.
Data Preparation:
df_clark_zip: A new DataFrame is created for Zip Code Analysis, which is essentially a copy of the df_clark DataFrame.
df_clark_avg: Another DataFrame is created to represent the average rent values for different bedroom configurations in Clark County. The data is grouped by the "Year" and the mean value of rents for different types of bedroom configurations (like Efficiency, One-Bedroom, etc.) is calculated. This DataFrame provides a yearly average of rent values.
The df_msa DataFrame is filtered to only include data for the fiscal years 2011-2024. This is done to ensure consistency in the year range when comparing with Clark County's data.
BedroomUnits_msa and BedroomUnits_clark: The DataFrames df_msa and df_clark_avg are transformed from wide format to long format using the gather function. This transformation makes it easier to handle and analyze the rent data based on different bedroom configurations.
Data Transformation:
The average FMR values in the BedroomUnits_clark DataFrame are rounded to whole numbers.

Then I worked with was the Annual Personal Income data from BEA.

Data Loading:
API_MSA: The dataset contains annual personal income data for the Portland-Vancouver-Hillsboro region and is loaded from the Annual Personal Income MSA.csv file.
API_Clark: The dataset contains annual personal income data specifically for Clark County and is loaded from the Annual Personal Income ClarkCounty.csv file.
Data Augmentation:
A new column, Statistical_Area, is added to both the API_MSA and API_Clark datasets. This column serves to indicate the statistical area to which the data belongs:
For API_MSA, the statistical area is set to "Portland-Vancouver-Hillsboro, OR-WA".
For API_Clark, the statistical area is set to "Clark County".
Data Combining:
The combined_data DataFrame is created by combining rows from both API_MSA and API_Clark. The bind_rows function is used for this purpose.
Before combining, specific columns are selected from each dataset using the select function. The selected columns are Year, Per capita personal income (dollars), and Statistical_Area.

Finally, I worked with the U.S. Census Bureau’s data. My plan is to use all of this data as indicators to get a holistic gauge at the socio and economic makeup of Clark County, WA. If the data represents a single year for all of Clark County, WA it comes from ACS 2022 1-year. If the data represents zip codes, it comes from ACS 2021 5-year.

Educational Attainment in Clark County
Data Loading:
Ed_Index: The dataset contains educational attainment data for Clark County, sourced from the ACS (American Community Survey) 2022 1-year estimate. The data is loaded from the Educational Attainment.csv file. The first few rows of this dataset are displayed to provide a quick view of its structure.
Data Reshaping:
Ed_Index_long: The Ed_Index dataset is transformed from a wide format to a long format using the gather function. This transformation results in two columns: education_level (representing different levels of education) and value (representing the percentage of individuals in each education level).
Data Transformation:
Grouping Educational Levels: The education_group column is added to the Ed_Index_long dataset. This column is derived based on the values in the education_level column and groups different levels of education into broader categories. For example, levels like "Nursery to 4th grade", "5th and 6th grade", etc., are grouped under the "K-12 no diploma" category.
Conversion to Numeric: The percentage values in the value column are converted from string format (with a '%' symbol) to numeric format.
Data Aggregation:
Ed_Index_aggregated: The Ed_Index_long dataset is aggregated based on the education_group column. The total percentage value for each educational group is calculated using the summarise function, resulting in the total_value column.
Metadata:
education_order: A vector is defined to specify the desired order for the educational groups. This vector can be used in subsequent analyses or visualizations to maintain a consistent order for the educational groups.

SNAP (Supplemental Nutrition Assistance Program) by Poverty Status for Households in Clark County
Data Loading:
SNAP_Index: The dataset contains data about SNAP by poverty status for households in Clark County, sourced from the ACS (American Community Survey) 2022 1-year estimate. The data is loaded from the SNAPbyPovertyClark.csv file. The structure of the dataset is briefly displayed using the head function.
Data Transformation:
Renaming Columns: The columns of the SNAP_Index dataset are renamed for clarity and ease of reference.
Converting Data Types: The percentage values in the columns are converted from string format (with a '%' symbol) to numeric format. This conversion is applied to all columns in the SNAP_Index dataset.
Reshaping Data:
SNAP_long: The SNAP_Index dataset is transformed from a wide format to a long format using the gather function. This transformation results in two columns: Category (representing the different SNAP and income categories) and Percentage (representing the percentage of households in each category).
SNAP_long_aggregated: Similarly, the SNAP_aggregated dataset is also transformed to a long format.
Data Aggregation:
SNAP_aggregated: The data in the SNAP_Index dataset is aggregated to compute total percentages for broader categories. For instance, the percentages of "SNAP recipients with income below poverty level" and "SNAP recipients with income at or above poverty level" are summed to get a total percentage for "SNAP Recipients".

Vacancy Status in Clark County
Data Loading:
Vacan_Index: The dataset contains data about the vacancy status of properties in Clark County, sourced from the ACS (American Community Survey) 2022 1-year estimate. The data is loaded from the VacancyStatusClark.csv file. A glimpse of the dataset's structure is shown using the head function.
Data Reshaping:
vacancy_long: The Vacan_Index dataset is transformed from a wide format to a long format using the gather function. This transformation results in two columns: Vacancy_Status (indicating the status of the property) and Percentage (representing the percentage of properties in each status).
Data Transformation:
Filtering Data: The "For migrant workers" category is filtered out from the vacancy_long dataset if its percentage value is zero.
Extracting Relevant Columns:
rental_data: Data related to properties "For rent" and "Rented, not occupied" is extracted into a new DataFrame.
efficiency_data: Data related to properties "For rent" and "Rented, not occupied" is extracted for efficiency analysis.
Adjusting Data: The percentage value for the "For rent" category in the Vacan_Index dataset is adjusted by subtracting the percentage of properties "For sale only".
Further Reshaping:
efficiency_long: The efficiency_data dataset is transformed from a wide format to a long format using the gather function, resulting in the Efficiency_Type and Percentage columns.

SNAP (Supplemental Nutrition Assistance Program) by Poverty Status for Households by Zip Code
Data Loading:
SNAP_shapefile: The dataset contains SNAP by poverty status data by zip code, sourced from the ACS (American Community Survey) 2021 5-year estimate. The data is loaded from the SNAPbyPovertyZip.shp shapefile.
Data Cleaning:
Removing Unwanted Columns: Columns in the SNAP_shapefile dataset that end with the letter "e" (indicating a processing error) are identified for removal, excluding the "name" column.
These identified columns are then removed from the dataset.
Inspecting the Modified Data: A plot of the modified shapefile data (SNAP_shapefile) is generated to visually inspect the data.
Data Transformation:
Percentage Calculation: Columns in the SNAP_shapefile dataset, excluding specific ones like "geoid", "name", "B22003001", and the geometry column, are identified for percentage calculation.
For each of these identified columns, the percentage value is calculated based on the total from the "B22003001" column. These percentage values are then rounded to one decimal place and added to the dataset.
Renaming Columns: A mapping (column_mapping) is defined to rename columns in the SNAP_shapefile dataset for clarity and ease of reference.
The percentage columns are also renamed based on the defined mapping.

Employment Status by Zip Code
Data Loading:
Employment_shapefile: The dataset contains employment status data by zip code, sourced from the ACS (American Community Survey) 2021 5-year estimate. The data is loaded from the EmploymentZip.shp shapefile. A plot of the data is generated for a quick visual inspection.
Data Cleaning:
Removing Unwanted Columns: Columns in the Employment_shapefile dataset that end with the letter "e" (indicating a processing error) are identified for removal, excluding the "name" column.
These identified columns are then removed from the dataset.
Inspecting the Modified Data: A plot of the modified shapefile data (Employment_shapefile) is generated to visually inspect the data.
Data Transformation:
Percentage Calculation: Columns in the Employment_shapefile dataset, excluding specific ones like "geoid", "name", "B23025001", and the geometry column, are identified for percentage calculation.
For each of these identified columns, the percentage value is calculated based on the total from the "B23025001" column. These percentage values are then rounded to one decimal place and added to the dataset.
Renaming Columns: A mapping (column_mapping) is defined to rename columns in the Employment_shapefile dataset for clarity and ease of reference.
The percentage columns are also renamed based on the defined mapping.

Hispanic or Latino Origin by Race by Zip Code
Data Loading:
Race_shapefile: The dataset contains Hispanic or Latino origin by race data by zip code, sourced from the ACS (American Community Survey) 2021 5-year estimate. The data is loaded from the RaceEthnZip.shp shapefile. An initial plot of the data is generated for a visual inspection.
Data Cleaning:
Removing Unwanted Columns: Columns in the Race_shapefile dataset ending with the letter "e" (indicating a processing error) are identified for removal, excluding the "name" column.
These identified columns are then removed from the dataset.
Inspecting the Modified Data: A plot of the modified shapefile data (Race_shapefile) is generated to visually inspect the data.
Data Transformation:
Percentage Calculation: Columns in the Race_shapefile dataset, excluding specific ones like "geoid", "name", "B03002001", and the geometry column, are identified for percentage calculation.
For each of these identified columns, the percentage value is calculated based on the total from the "B03002001" column. These percentage values are then rounded to one decimal place and added to the dataset.
Renaming Columns: A mapping (column_mapping) is defined to rename columns in the Race_shapefile dataset for clarity and ease of reference.
The percentage columns are also renamed based on the defined mapping.
White Alone Group: The White_Alone group is directly derived from the White alone column in the Race_shapefile. This group represents the population that identifies as "White" alone, not in combination with any other race.
People of Color Group: The People_of_Color group is an aggregation of various racial and ethnic categories other than "White alone". 
It includes:
Black or African American alone: Individuals who identify solely as Black or African American.
American Indian and Alaska Native alone: Individuals who identify solely as American Indian or Alaska Native.
Asian alone: Individuals who identify solely as Asian.
Native Hawaiian and Other Pacific Islander alone: Individuals who identify solely as Native Hawaiian or Other Pacific Islander.
Some other race alone: Individuals who do not fit into any of the provided racial categories.
Two or more races: Individuals who identify with two or more racial categories.
Hispanic or Latino: This represents individuals who identify as Hispanic or Latino, which is an ethnic category and can be of any race.

Median Household Income by Zip Code
Data Loading:
Income_shapefile: The dataset contains median household income data by zip code, sourced from the ACS (American Community Survey) 2021 5-year estimate. The data is loaded from the MedianIncomeZip.shp shapefile. An initial plot of the data is generated for a quick visual inspection.
Data Cleaning:
Removing Unwanted Columns: Columns in the Income_shapefile dataset that end with the letter "e" (indicating a processing error) are identified for removal, excluding the "name" column.
These identified columns are then removed from the dataset.
Inspecting the Modified Data: A plot of the modified shapefile data (Income_shapefile) is generated to visually inspect the data.
Data Transformation:
Renaming Columns: A mapping (column_mapping) is defined to rename columns in the Income_shapefile dataset for clarity and ease of reference.
This mapping is then applied to rename the columns in the dataset.

Rent Prices by Zip Code
Data Loading:
df_clark_zip: This dataset contains rental prices for different bedroom unit types across various zip codes for different years.
shapefile: The dataset contains shape data for zip codes (polygon geometries representing zip code areas). It's sourced from a Clark County GIS hub.
Data Transformation:
Converting Wide to Long Format:
The BedroomUnits_Zip dataframe is created from df_clark_zip by transforming it into a long format. This involves moving the different bedroom unit types (like "Efficiency", "One-Bedroom", etc.) into a single column (BedroomUnits) and their corresponding rent values into another column (Rent). This is done while retaining the Year and ZIP columns.
Data Merging:
The zip code shape data from shapefile is merged with the rent data in BedroomUnits_Zip based on the ZIP code. This results in the merged_data dataframe which combines geometrical information about each zip code with its corresponding rent prices for different bedroom unit types and years.
Geospatial Analysis:
Computing Centroids: For each zip code area in efficiency_data, its centroid (geographical center point) is computed. The resulting centroids dataframe contains these centroids for each zip code.
Filtering Data: The selected_data dataframe is created by filtering merged_data for a specific bedroom unit type ("Efficiency") and a specific year (2023).
Coordinate Reference System (CRS) Transformation:The selected_data dataframe's CRS is transformed to WGS 84 (EPSG:4326), which is a common CRS for latitude and longitude coordinates.

3. Data visualization section that integrates improvements to previously submitted graphics- or new graphics that improve upon your previous graphics (10 pts)

I have created many new graphs. Below are a few that I have improved upon. These are just a few of all the graphs I have created and modified.


```{r load data for visualizations}

# Pull Portland-Vancouver-Hillsboro Data
df_msa <- read_csv("Data/FMRs By FY.csv") # Fair Market Rents (FMRs) for FY2000-2024
# Pull Clark County Data
df_clark <- read_csv("Data/FY Small Area FMRs.csv") # Fair Market Rents (FMRs) for FY2011-2024
# Create DataFrame for Zip Code Analysis
df_clark_zip <- df_clark
# Create DataFrame for MSA Comparison
df_clark_avg <- df_clark %>%
  group_by(Year) %>%
  summarise(
    `Efficiency` = mean(`Efficiency`, na.rm = TRUE),
    `One-Bedroom` = mean(`One-Bedroom`, na.rm = TRUE), 
    `Two-Bedroom` = mean(`Two-Bedroom`, na.rm = TRUE), 
    `Three-Bedroom` = mean(`Three-Bedroom`, na.rm = TRUE), 
    `Four-Bedroom` = mean(`Four-Bedroom`, na.rm = TRUE), 
  ) %>%
  ungroup()
# Filter MSA Data to reflect FY2011-24 and match the FY Data for Clark County
df_msa <- subset(df_msa, Year >= 2011 & Year <= 2024)
# Create long data for FMRs
BedroomUnits_msa <- tidyr::gather(df_msa, BedroomUnits, FMRs, -Year)
BedroomUnits_clark <- tidyr::gather(df_clark_avg, BedroomUnits, FMRs, -Year)
# Round Clark County FMRs average to whole number
BedroomUnits_clark$FMRs <- round(BedroomUnits_clark$FMRs, 0)
# Specify the order of Bedroom Units
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")
# Factorize 'BedroomUnits' with specified order in BedroomUnits_clark
BedroomUnits_clark$BedroomUnits <- factor(BedroomUnits_clark$BedroomUnits, levels = ordered_levels)
# Factorize 'BedroomUnits' with specified order in BedroomUnits_msa
BedroomUnits_msa$BedroomUnits <- factor(BedroomUnits_msa$BedroomUnits, levels = ordered_levels)
# Add a new column 'Statistical Area'
names(BedroomUnits_clark)[names(BedroomUnits_clark) == "Source"] <- "Statistical Area"
names(BedroomUnits_msa)[names(BedroomUnits_msa) == "Source"] <- "Statistical Area"
BedroomUnits_clark$`Statistical Area` <- "Clark County"
BedroomUnits_msa$`Statistical Area` <- "Portland-Vancouver-Hillsboro, OR-WA"
# Combine the datasets
combined_data <- rbind(BedroomUnits_clark, BedroomUnits_msa)
# Set ordered levels for BedroomUnits
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")
combined_data$BedroomUnits <- factor(combined_data$BedroomUnits, levels = ordered_levels)
create_plotly_scatter_plot <- function(unit) {
  # Subset data for the specified bedroom unit
  subset_data <- subset(combined_data, BedroomUnits == unit)
  # Create custom hover text
  hover_text <- paste("The FMRs was $", subset_data$FMRs, " for the Fiscal Year ", subset_data$Year, " in ", subset_data$`Statistical Area`, sep = "")
  # Create plotly scatter plot
  p <- plot_ly(data = subset_data, x = ~Year, y = ~FMRs, color = ~`Statistical Area`, type = 'scatter', mode = 'markers',
               text = hover_text, hoverinfo = "text") %>%
    layout(title = paste("Comparison of FMRs for", unit),
           xaxis = list(title = "Fiscal Year", tickmode = "linear", tick0 = 2011, dtick = 1),
           yaxis = list(title = "FMRs", tickformat = "$"))
  return(p)
}
# Create individual plot for each bedroom unit
for (unit in ordered_levels) {
  print(create_plotly_scatter_plot(unit))
}

# Pull Portland-Vancouver-Hillsboro Data
API_MSA <- read_csv("Data/Annual Personal Income MSA.csv")
# Pull Clark County Data
API_Clark <- read_csv("Data/Annual Personal Income ClarkCounty.csv")
# Add a new variable to each dataset to indicate the Statistical Area
API_MSA <- API_MSA %>% mutate(Statistical_Area = "Portland-Vancouver-Hillsboro, OR-WA")
API_Clark <- API_Clark %>% mutate(Statistical_Area = "Clark County")
# Combine Data
combined_data <- bind_rows(
  select(API_MSA, Year, `Per capita personal income (dollars)`, Statistical_Area),
  select(API_Clark, Year, `Per capita personal income (dollars)`, Statistical_Area)
)
# Create the interactive time series graph for comparison
plot <- plot_ly(data = combined_data, x = ~Year, y = ~`Per capita personal income (dollars)`, color = ~Statistical_Area, type = 'scatter', mode = 'lines+markers',
                text = ~paste("The personal income was $", `Per capita personal income (dollars)`, " for the Year ", Year, " in ", Statistical_Area, sep = ""),
                hoverinfo = "text") %>%
  layout(title = "Personal income in Clark County from 1969 to 2021",
         xaxis = list(title = "Year", dtick = 5),  # Set tick distance on x-axis
         yaxis = list(title = "Personal Income", tickprefix = "$", dtick = 10000, rangemode = "tozero"))  # Set tick distance and prefix on y-axis
# Show the plot
plot

# Pull Clark County Educational Attainment Data from ACS 2022 1-year
Ed_Index <- read_csv("Data/Educational Attainment.csv")
# Convert wide format to long format
Ed_Index_long <- Ed_Index %>%
  gather(key = "education_level", value = "value")
# Grouping educational levels based on categories
Ed_Index_long$education_group <- with(Ed_Index_long, case_when(
  education_level == "No schooling completed" ~ "No Formal Education",
  education_level %in% c("Nursery to 4th grade", "5th and 6th grade", "7th and 8th grade", 
                         "9th grade", "10th grade", "11th grade", "12th grade, no diploma") ~ "K-12 no diploma",
  education_level %in% c("Regular high school diploma", "GED or alternative credential") ~ "High School diploma, GED or alternative credential",
  education_level %in% c("Some college, less than 1 year", "Some college, 1 or more years, no degree", 
                         "Associate's degree") ~ "Some College or Associates Degree",
  education_level == "Bachelor's degree" ~ "Undergraduate",
  education_level %in% c("Master's degree", "Professional school degree", "Doctorate degree") ~ "Graduate",
  TRUE ~ as.character(education_level)
))
# Convert percentage values to numeric
Ed_Index_long$value <- as.numeric(gsub("%", "", Ed_Index_long$value))
# Aggregate values for each educational group
Ed_Index_aggregated <- Ed_Index_long %>%
  group_by(education_group) %>%
  summarise(total_value = sum(value, na.rm = TRUE))
# Define the order for the educational groups
education_order <- c("No Formal Education", "K-12 no diploma", "High School diploma, GED or alternative credential", "Some College or Associates Degree", "Undergraduate", "Graduate")
# Vertical Bar Plot
ggplot(Ed_Index_aggregated, aes(x = factor(education_group, levels = education_order), y = total_value, fill = education_group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", total_value)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  labs(title = "2022 Educational Attainment in Clark County, WA",
       x = "",
       y = "Percent Completed") +
  theme_minimal() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),  # Made text bold
        plot.title = element_text(hjust = 0))

# Pull Median Household Income by Zip from ACS 2021 5-year
Income_shapefile <- st_read("Data/MedianIncomeZip.shp")
# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(Income_shapefile)[grepl("e$", names(Income_shapefile)) & names(Income_shapefile) != "name"]
# Remove the identified columns
Income_shapefile <- Income_shapefile[, !names(Income_shapefile) %in% columns_to_remove]
# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B19013001" = "Median household income"
)
# Get the name of the geometry column
geom_col_name <- attr(Income_shapefile, "sf_column")
# Exclude the geometry column when renaming
columns_to_rename <- setdiff(names(Income_shapefile), geom_col_name)
# Correctly apply the column_mapping to rename the columns
names(Income_shapefile)[names(Income_shapefile) %in% names(column_mapping)] <- column_mapping[names(column_mapping)]
# Create the graph
tm_shape(Income_shapefile) + 
  tm_borders() + 
  tm_fill(col = "Median household income", 
          palette = "-viridis", 
          title = "Median household income",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

# Pull SNAP by Poverty Status Data by Zip from ACS 2021 5-year
SNAP_shapefile <- st_read("Data/SNAPbyPovertyZip.shp")
column_names <- names(SNAP_shapefile)
# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(SNAP_shapefile)[grepl("e$", names(SNAP_shapefile)) & names(SNAP_shapefile) != "name"]
# Remove the identified columns
SNAP_shapefile <- SNAP_shapefile[, !names(SNAP_shapefile) %in% columns_to_remove]
# Save the modified shapefile `st_write(SNAP_shapefile, "Data/ModifiedVacancyStatusZip.shp")`
# Transform data to percents
# Identify columns to calculate percentage for, exclude columns like "geoid", "name", and "B22003001" 
# Get the name of the geometry column
geom_col_name <- attr(SNAP_shapefile, "sf_column")
# Exclude the geometry column  when identifying columns for percentage calculation
columns_to_calculate <- setdiff(names(SNAP_shapefile), c("geoid", "name", "B22003001", geom_col_name))
# Calculate and round percentage for each column
for (col in columns_to_calculate) {
  if (is.numeric(SNAP_shapefile[[col]]) && is.numeric(SNAP_shapefile$B22003001)) {
    new_col_name <- paste0(col, "_pct")
    percentage_values <- (SNAP_shapefile[[col]] / SNAP_shapefile$B22003001) * 100
    SNAP_shapefile[[new_col_name]] <- as.numeric(round(percentage_values, 1))
  } else {
    cat(paste("Skipping non-numeric column:", col, "\n"))
  }
}
# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B22003001" = "Total",
  "B22003002" = "Household received SNAP",
  "B22003003" = "Income below poverty level and received SNAP",
  "B22003004" = "Income at or above poverty level",
  "B22003005" = "Household did not receive SNAP",
  "B22003006" = "Income below poverty level and did not receive SNAP",
  "B22003007" = "Income at or above poverty level"
)
# Rename the percentage columns
pct_columns <- paste0(columns_to_calculate, "_pct")
old_pct_names <- pct_columns
new_pct_names <- column_mapping[columns_to_calculate]
names(SNAP_shapefile)[names(SNAP_shapefile) %in% old_pct_names] <- new_pct_names
# Remove rows where the name is "Clark County, WA"
SNAP_shapefile <- SNAP_shapefile[SNAP_shapefile$name != "Clark County, WA", ]
# Function to create an interactive map for a specified column
create_map <- function(data, column_name) {
  # Create hover text for the specified column
  hover_text <- paste0(data$name, " has ", round(data[[column_name]], 1), "%")
  # Define the color map
  color_map <- colorNumeric(palette = viridis(100, direction = -1), domain = range(data[[column_name]], na.rm = TRUE))
  # Convert the sf object to a Spatial object for compatibility with leaflet
  data_sp <- as(data, "Spatial")
  # Create the map
  leaflet(data_sp) %>%
    addProviderTiles(providers$OpenStreetMap) %>%
    addPolygons(
      fillColor = ~color_map(data[[column_name]]),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.5,
      highlight = highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.7,
        bringToFront = TRUE
      ),
      label = ~hover_text,
      labelOptions = labelOptions(
        style = list("font-weight" = "bold"),
        textsize = "15px",
        direction = "auto"
      )
    ) %>%
    addLegend(
      pal = color_map,
      values = data[[column_name]],
      opacity = 0.7,
      title = paste(column_name, "by ZIP Code (%)"),
      position = "bottomright",
      labFormat = labelFormat(suffix = "%")
    )
}
# Create maps for the specified columns
create_map(SNAP_shapefile, "Household received SNAP")

# Pull Data and Clark County Shapefile (https://hub-clarkcountywa.opendata.arcgis.com/pages/digital-gis-data-download)
shapefile <- st_read("Data/Zipcode.shp")
# Transform data to long format
BedroomUnits_Zip <- tidyr::gather(df_clark_zip, BedroomUnits, "Rent", -Year, -ZIP)
# merge shapefile into long data
merged_data <- left_join(shapefile, BedroomUnits_Zip, by = c("ZIPCODE" = "ZIP"))
# Filter data for a specific Bedroom Unit and Year (e.g., "One-Bedroom" and 2018)
selected_data <- subset(merged_data, BedroomUnits == "One-Bedroom" & Year == 2018)
# transform your data to the WGS 84 CRS
selected_data <- st_transform(selected_data, 4326)
# Define a function to create a leaflet map for rent prices
create_rent_map <- function(data, column_name) {
  # Define the color palette
  color_map <- colorNumeric(palette = viridis(100, direction = -1), domain = data[[column_name]], na.color = "transparent")
  # Create hover text
  data$hover_text <- paste0("40th percentile rent = $", round(data[[column_name]], 2), " in ", data$ZIPCODE)
  # Create the leaflet map
  map <- leaflet(data) %>%
    addProviderTiles(providers$OpenStreetMap) %>%
    addPolygons(
      fillColor = ~color_map(data[[column_name]]),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.7,
      highlight = highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.9,
        bringToFront = TRUE
      ),
      label = ~hover_text,
      labelOptions = labelOptions(
        style = list("font-weight" = "bold"),
        textsize = "15px",
        direction = "auto"
      )
    ) %>%
    addLegend(
      pal = color_map,
      values = data[[column_name]],
      opacity = 0.7,
      title = column_name,
      position = "bottomright",
      labFormat = labelFormat(prefix = "$")
    )
  # Add title indicating Bedroom Unit and Year
  map <- addControl(map, 
                    html = paste("Bedroom Unit:", unique(data$BedroomUnits), "<br>Year:", unique(data$Year)),
                    position = "topright")
  return(map)
}
# Use the function to create a map for the "Rent" column
create_rent_map(selected_data, "Rent")

```




4. a section for each of the new techniques applied containing the answers to the above questions in complete detail and paragraph form (30 pts)

```{r data exploration techniques 1}

# Pull Portland-Vancouver-Hillsboro Data
df_msa <- read_csv("Data/FMRs By FY.csv") # Fair Market Rents (FMRs) for FY2000-2024
# Pull Clark County Data
df_clark <- read_csv("Data/FY Small Area FMRs.csv") # Fair Market Rents (FMRs) for FY2011-2024
# Create DataFrame for Zip Code Analysis
df_clark_zip <- df_clark
# Create DataFrame for MSA Comparison
df_clark_avg <- df_clark %>%
  group_by(Year) %>%
  summarise(
    `Efficiency` = mean(`Efficiency`, na.rm = TRUE),
    `One-Bedroom` = mean(`One-Bedroom`, na.rm = TRUE), 
    `Two-Bedroom` = mean(`Two-Bedroom`, na.rm = TRUE), 
    `Three-Bedroom` = mean(`Three-Bedroom`, na.rm = TRUE), 
    `Four-Bedroom` = mean(`Four-Bedroom`, na.rm = TRUE), 
  ) %>%
  ungroup()
# Filter MSA Data to reflect FY2011-24 and match the FY Data for Clark County
df_msa <- subset(df_msa, Year >= 2011 & Year <= 2024)
# Create long data for FMRs
BedroomUnits_msa <- tidyr::gather(df_msa, BedroomUnits, FMRs, -Year)
BedroomUnits_clark <- tidyr::gather(df_clark_avg, BedroomUnits, FMRs, -Year)
# Round Clark County FMRs average to whole number
BedroomUnits_clark$FMRs <- round(BedroomUnits_clark$FMRs, 0)
# Specify the order of Bedroom Units
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")
# Factorize 'BedroomUnits' with specified order in BedroomUnits_clark
BedroomUnits_clark$BedroomUnits <- factor(BedroomUnits_clark$BedroomUnits, levels = ordered_levels)
# Factorize 'BedroomUnits' with specified order in BedroomUnits_msa
BedroomUnits_msa$BedroomUnits <- factor(BedroomUnits_msa$BedroomUnits, levels = ordered_levels)
# Add a new column 'Statistical Area'
names(BedroomUnits_clark)[names(BedroomUnits_clark) == "Source"] <- "Statistical Area"
names(BedroomUnits_msa)[names(BedroomUnits_msa) == "Source"] <- "Statistical Area"
BedroomUnits_clark$`Statistical Area` <- "Clark County"
BedroomUnits_msa$`Statistical Area` <- "Portland-Vancouver-Hillsboro, OR-WA"
# Combine the datasets
combined_data <- rbind(BedroomUnits_clark, BedroomUnits_msa)
# Set ordered levels for BedroomUnits
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")
combined_data$BedroomUnits <- factor(combined_data$BedroomUnits, levels = ordered_levels)
create_plotly_scatter_plot <- function(unit) {
  # Subset data for the specified bedroom unit
  subset_data <- subset(combined_data, BedroomUnits == unit)
  # Create custom hover text
  hover_text <- paste("The FMRs was $", subset_data$FMRs, " for the Fiscal Year ", subset_data$Year, " in ", subset_data$`Statistical Area`, sep = "")
  # Create plotly scatter plot
  p <- plot_ly(data = subset_data, x = ~Year, y = ~FMRs, color = ~`Statistical Area`, type = 'scatter', mode = 'markers',
               text = hover_text, hoverinfo = "text") %>%
    layout(title = paste("Comparison of FMRs for", unit),
           xaxis = list(title = "Fiscal Year", tickmode = "linear", tick0 = 2011, dtick = 1),
           yaxis = list(title = "FMRs", tickformat = "$"))
  return(p)
}
# Create individual plot for each bedroom unit
for (unit in ordered_levels) {
  print(create_plotly_scatter_plot(unit))
}

```


Figure 1: Scatter plot depicting the comparison of FMRs for various bedroom units between Clark County and the Portland-Vancouver-Hillsboro area from FY2011 to FY2024.
Method 1: Comparison of Fair Market Rents (FMRs) for Different Bedroom Units

The rationale for the Selection of Fair Market Rents (FMRs) is a vital indicator of housing affordability. By comparing the FMRs for different bedroom units in Clark County to the broader Portland-Vancouver-Hillsboro area, we can gain insights into the local housing market's dynamics. Understanding FMRs directly aligns with assessing housing affordability. The disparity in rent prices for different units can provide a comprehensive understanding of housing accessibility for different income groups. The scatter plot illustrates the trend in FMRs for different bedroom units across the years. The comparison between Clark County and the broader region allows for a relative assessment of housing costs. The insights from the FMR comparison can guide housing policies and strategies aimed at ensuring affordability. Recognizing areas with higher FMRs can help target interventions and support.


```{r data exploration techniques 2}
# Pull Clark County Educational Attainment Data from ACS 2022 1-year
Ed_Index <- read_csv("Data/Educational Attainment.csv")
# Convert wide format to long format
Ed_Index_long <- Ed_Index %>%
  gather(key = "education_level", value = "value")
# Grouping educational levels based on categories
Ed_Index_long$education_group <- with(Ed_Index_long, case_when(
  education_level == "No schooling completed" ~ "No Formal Education",
  education_level %in% c("Nursery to 4th grade", "5th and 6th grade", "7th and 8th grade", 
                         "9th grade", "10th grade", "11th grade", "12th grade, no diploma") ~ "K-12 no diploma",
  education_level %in% c("Regular high school diploma", "GED or alternative credential") ~ "High School diploma, GED or alternative credential",
  education_level %in% c("Some college, less than 1 year", "Some college, 1 or more years, no degree", 
                         "Associate's degree") ~ "Some College or Associates Degree",
  education_level == "Bachelor's degree" ~ "Undergraduate",
  education_level %in% c("Master's degree", "Professional school degree", "Doctorate degree") ~ "Graduate",
  TRUE ~ as.character(education_level)
))
# Convert percentage values to numeric
Ed_Index_long$value <- as.numeric(gsub("%", "", Ed_Index_long$value))
# Aggregate values for each educational group
Ed_Index_aggregated <- Ed_Index_long %>%
  group_by(education_group) %>%
  summarise(total_value = sum(value, na.rm = TRUE))
# Define the order for the educational groups
education_order <- c("No Formal Education", "K-12 no diploma", "High School diploma, GED or alternative credential", "Some College or Associates Degree", "Undergraduate", "Graduate")
# Vertical Bar Plot
ggplot(Ed_Index_aggregated, aes(x = factor(education_group, levels = education_order), y = total_value, fill = education_group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", total_value)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  labs(title = "2022 Educational Attainment in Clark County, WA",
       x = "",
       y = "Percent Completed") +
  theme_minimal() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),  # Made text bold
        plot.title = element_text(hjust = 0))
```



Figure 2: Bar chart showcasing the distribution of the population based on different levels of educational attainment in Clark County for the year 2022. The bar chart reveals the percentage of the population that has achieved various education levels. This provides an understanding of the educational landscape in Clark County.
Method 2: Analysis of Educational Attainment

The rationale for using Educational attainment as an index measure is that it is a crucial socio-economic factor that influences income levels, employment opportunities, and overall quality of life. It serves as a foundation for understanding the socio-economic fabric of Clark County. Education plays a pivotal role in shaping equity. Analyzing educational attainment helps gauge the accessibility and quality of education, which directly ties into the broader theme of equity and housing. The educational attainment data serves as a foundation for understanding the socio-economic landscape. Areas with lower educational attainment might require targeted interventions, ranging from educational programs to housing support.

```{r data exploration techniques  3}
# Pull Data and Clark County Shapefile (https://hub-clarkcountywa.opendata.arcgis.com/pages/digital-gis-data-download)
shapefile <- st_read("Data/Zipcode.shp")
# Transform data to long format
BedroomUnits_Zip <- tidyr::gather(df_clark_zip, BedroomUnits, "Rent", -Year, -ZIP)
# merge shapefile into long data
merged_data <- left_join(shapefile, BedroomUnits_Zip, by = c("ZIPCODE" = "ZIP"))
# Filter data for a specific Bedroom Unit and Year (e.g., "One-Bedroom" and 2018)
selected_data <- subset(merged_data, BedroomUnits == "One-Bedroom" & Year == 2018)
# transform your data to the WGS 84 CRS
selected_data <- st_transform(selected_data, 4326)
# Define a function to create a leaflet map for rent prices
create_rent_map <- function(data, column_name) {
  # Define the color palette
  color_map <- colorNumeric(palette = viridis(100, direction = -1), domain = data[[column_name]], na.color = "transparent")
  # Create hover text
  data$hover_text <- paste0("40th percentile rent = $", round(data[[column_name]], 2), " in ", data$ZIPCODE)
  # Create the leaflet map
  map <- leaflet(data) %>%
    addProviderTiles(providers$OpenStreetMap) %>%
    addPolygons(
      fillColor = ~color_map(data[[column_name]]),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.7,
      highlight = highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.9,
        bringToFront = TRUE
      ),
      label = ~hover_text,
      labelOptions = labelOptions(
        style = list("font-weight" = "bold"),
        textsize = "15px",
        direction = "auto"
      )
    ) %>%
    addLegend(
      pal = color_map,
      values = data[[column_name]],
      opacity = 0.7,
      title = column_name,
      position = "bottomright",
      labFormat = labelFormat(prefix = "$")
    )
  # Add title indicating Bedroom Unit and Year
  map <- addControl(map, 
                    html = paste("Bedroom Unit:", unique(data$BedroomUnits), "<br>Year:", unique(data$Year)),
                    position = "topright")
  return(map)
}
# Use the function to create a map for the "Rent" column
create_rent_map(selected_data, "Rent")
```

Figure 3: Map showcasing rent prices by Zip Code for a specific Bedroom Unit and Year in Clark County.
Method 3: Geospatial Analysis of Rent Prices by Zip Code

The rationale for using a geospatial analysis is that it offers a visual representation of data on a map, providing a clearer understanding of regional disparities. Analyzing rent prices by Zip Code can help pinpoint areas where housing is either more affordable or more expensive. Housing affordability varies across regions. By mapping rent prices, we can visually identify areas that might be more challenging for residents due to high rents, aiding in the broader goal of ensuring equitable housing opportunities. Geospatial insights offer a clear picture of the regional disparities in rent prices. These insights can guide housing policies, ensuring that interventions are targeted at regions where they are most needed.

5. Conclusion that includes how you are going to use the analysis to better understand how to complete the remainder of your project (5 pts)

I am really happy were where I am at now with my project. I had no prior Geospatial analysis experience before, but I have been able to produce Zip Code graphs from Clark County, WA that I am proud of. What are my next steps? I need to develop statistical models. My idea is that I want to create a model that looks at the various socio and economic index's in Clark County, WA and rates neighborhoods/Zip Codes. Are BOPIC (Black, Indigenous, People of Color) individuals more likely to live in certain neighborhoods in Clark County? Is a neighborhood/Zip code area with a lower than average median income, more likely to have a higher than average population of households receiving food stamps, and what is the race demographic in that area relative to Neighborhoods/Zip Codes around it? Also, for neighborhoods/Zip Codes with lower than average median incomes, what does the rent prices look like in those neighborhoods/Zip Codes compared to other neighborhoods/Zip Codes within Clark County, WA. 

Data Engineering for Fair Market Rents (FMRs) in MSA and Clark County

```{r FMRs for Statistical Area - Data Cleaning}

# Pull Portland-Vancouver-Hillsboro Data
df_msa <- read_csv("Data/FMRs By FY.csv") # Fair Market Rents (FMRs) for FY2000-2024

# Pull Clark County Data
df_clark <- read_csv("Data/FY Small Area FMRs.csv") # Fair Market Rents (FMRs) for FY2011-2024

head(df_clark)
head(df_msa)

# Create DataFrame for Zip Code Analysis
df_clark_zip <- df_clark

# Create DataFrame for MSA Comparison
df_clark_avg <- df_clark %>%
  group_by(Year) %>%
  summarise(
    `Efficiency` = mean(`Efficiency`, na.rm = TRUE),
    `One-Bedroom` = mean(`One-Bedroom`, na.rm = TRUE), 
    `Two-Bedroom` = mean(`Two-Bedroom`, na.rm = TRUE), 
    `Three-Bedroom` = mean(`Three-Bedroom`, na.rm = TRUE), 
    `Four-Bedroom` = mean(`Four-Bedroom`, na.rm = TRUE), 
  ) %>%
  ungroup()

# Filter MSA Data to reflect FY2011-24 and match the FY Data for Clark County
df_msa <- subset(df_msa, Year >= 2011 & Year <= 2024)

# Create long data for FMRs
BedroomUnits_msa <- tidyr::gather(df_msa, BedroomUnits, FMRs, -Year)
BedroomUnits_clark <- tidyr::gather(df_clark_avg, BedroomUnits, FMRs, -Year)

# Round Clark County FMRs average to whole number
BedroomUnits_clark$FMRs <- round(BedroomUnits_clark$FMRs, 0)

cor(df_msa)
pairs(df_msa)

cor(df_clark)
pairs(df_clark)

head(df_clark_avg)
head(df_clark_zip)
head(BedroomUnits_clark)
head(BedroomUnits_msa)

```



Exploratory Data Analysis for Fair Market Rents (FMRs) in MSA and Clark County

```{r FMRs for Statistical Area - EDA}

# Specify the order of Bedroom Units
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")

# Factorize 'BedroomUnits' with specified order in BedroomUnits_clark
BedroomUnits_clark$BedroomUnits <- factor(BedroomUnits_clark$BedroomUnits, levels = ordered_levels)

# Factorize 'BedroomUnits' with specified order in BedroomUnits_msa
BedroomUnits_msa$BedroomUnits <- factor(BedroomUnits_msa$BedroomUnits, levels = ordered_levels)

# Line Plot for BedroomUnits_clark
ggplot(BedroomUnits_clark, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_line() +
  labs(title = "Fair Market Rents (FMRs) in Clark County",
       x = "Fiscal Year",
       y = "FMRs",
       color = "Bedroom Units") +
  scale_x_continuous(breaks = seq(min(BedroomUnits_clark$Year), max(BedroomUnits_clark$Year), 1), 
                     limits = c(min(BedroomUnits_clark$Year), max(BedroomUnits_clark$Year))) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Line Plot for BedroomUnits_msa
ggplot(BedroomUnits_msa, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_line() +
  labs(title = "Fair Market Rents (FMRs) in Portland-Vancouver-Hillsboro",
       x = "Fiscal Year",
       y = "FMRs",
       color = "Bedroom Units") +
  scale_x_continuous(breaks = seq(min(BedroomUnits_msa$Year), max(BedroomUnits_msa$Year), 1), 
                     limits = c(min(BedroomUnits_msa$Year), max(BedroomUnits_msa$Year))) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Box Plot for BedroomUnits_clark
ggplot(BedroomUnits_clark, aes(x = BedroomUnits, y = FMRs, fill = BedroomUnits)) +
  geom_boxplot() +
  labs(title = "Distribution of FMRs in Clark County",
       y = "FMRs",
       x = NULL, 
       fill = "Bedroom Units") + 
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) 

# Box Plot for BedroomUnits_msa
ggplot(BedroomUnits_msa, aes(x = BedroomUnits, y = FMRs, fill = BedroomUnits)) +
  geom_boxplot() +
  labs(title = "Distribution of FMRs in Portland-Vancouver-Hillsboro",
       y = "FMRs",
       x = NULL, 
       fill = "Bedroom Units") + 
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5)) 

# Scatter Plot for Time Series Analysis for BedroomUnits_clark
ggplot(BedroomUnits_clark, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_point() +
  labs(title = "FMRs in Clark County through the years",
       y = "FMRs",
       x = "Fiscal Year",
       color = "Bedroom Units") + 
  scale_y_continuous(labels = scales::dollar_format(prefix = "$")) + 
  scale_x_continuous(breaks = seq(2011, 2024, 1), limits = c(2011, 2024)) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Scatter Plot for Time Series Analysis for BedroomUnits_msa
ggplot(BedroomUnits_msa, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_point() +
  labs(title = "FMRs in Portland-Vancouver-Hillsboro through the years",
       y = "FMRs",
       x = "Fiscal Year",
       color = "Bedroom Units") + 
  scale_y_continuous(labels = scales::dollar_format(prefix = "$")) + 
  scale_x_continuous(breaks = seq(2011, 2024, 1), limits = c(2011, 2024)) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

# Faceted Line Plot for BedroomUnits_clark
ggplot(BedroomUnits_clark, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_line() +
  labs(title = "Fair Market Rents (FMRs) in Clark County",
       x = "Fiscal Year",
       y = "FMRs",
       color = "Bedroom Units") +
  scale_x_continuous(breaks = seq(min(BedroomUnits_clark$Year), max(BedroomUnits_clark$Year), 3), 
                     limits = c(min(BedroomUnits_clark$Year), max(BedroomUnits_clark$Year))) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~BedroomUnits, scales = "free_y") # Faceting by BedroomUnits

# Faceted Line Plot for BedroomUnits_msa
ggplot(BedroomUnits_msa, aes(x = Year, y = FMRs, color = BedroomUnits)) +
  geom_line() +
  labs(title = "Fair Market Rents (FMRs) in Portland-Vancouver-Hillsboro, OR-WA",
       x = "Fiscal Year",
       y = "FMRs",
       color = "Bedroom Units") +
  scale_x_continuous(breaks = seq(min(BedroomUnits_msa$Year), max(BedroomUnits_msa$Year), 3), 
                     limits = c(min(BedroomUnits_msa$Year), max(BedroomUnits_msa$Year))) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~BedroomUnits, scales = "free_y") # Faceting by BedroomUnits

```




```{r FMRs for Statistical Area - Clark vs. MSA}

# Add a new column 'Statistical Area'
names(BedroomUnits_clark)[names(BedroomUnits_clark) == "Source"] <- "Statistical Area"
names(BedroomUnits_msa)[names(BedroomUnits_msa) == "Source"] <- "Statistical Area"

BedroomUnits_clark$`Statistical Area` <- "Clark County"
BedroomUnits_msa$`Statistical Area` <- "Portland-Vancouver-Hillsboro, OR-WA"

# Combine the datasets
combined_data <- rbind(BedroomUnits_clark, BedroomUnits_msa)

# Set ordered levels for BedroomUnits
ordered_levels <- c("Four-Bedroom", "Three-Bedroom", "Two-Bedroom", "One-Bedroom", "Efficiency")
combined_data$BedroomUnits <- factor(combined_data$BedroomUnits, levels = ordered_levels)

# Faceted Line Plot with combined data
ggplot(combined_data, aes(x = Year, y = FMRs, color = `Statistical Area`, linetype = `Statistical Area`)) +
  geom_line(linewidth = 1.5) +  # Adjusted line size
  labs(title = "Comparison of Fair Market Rents (FMRs)",
       x = "Fiscal Year",
       y = "FMRs") +
  scale_x_continuous(breaks = seq(min(combined_data$Year), max(combined_data$Year), 3),
  limits = c(min(combined_data$Year), max(combined_data$Year))) +
  scale_y_continuous(labels = scales::dollar) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~BedroomUnits, scales = "free_y") # Faceting by BedroomUnits

create_plot <- function(unit) {
  # Filter the combined_data for the specified bedroom unit and years 2011-2021
  filtered_data <- subset(combined_data, BedroomUnits == unit & Year >= 2011 & Year <= 2021)

  ggplot(filtered_data, aes(x = Year, y = FMRs, color = `Statistical Area`, linetype = `Statistical Area`)) +
    geom_line(linewidth = 1.5) +  # Adjusted line size
    labs(title = paste("Comparison of FMRs for", unit, " (2011-2021)"),
         x = "Fiscal Year",
         y = "FMRs") +
    scale_x_continuous(breaks = seq(2011, 2021, 1), limits = c(2011, 2021)) +
    scale_y_continuous(labels = scales::dollar) +
    scale_color_brewer(palette = "Dark2") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}


# Create individual plot for each bedroom unit
for (unit in ordered_levels) {
  print(create_plot(unit))
}

# Function to create a scatter plot for a given bedroom unit
create_scatter_plot <- function(unit) {
  ggplot(subset(combined_data, BedroomUnits == unit), aes(x = Year, y = FMRs, color = `Statistical Area`)) +
    geom_point(size = 3, alpha = 0.7) +  # Adjusted point size and transparency
    labs(title = paste("Comparison of FMRs for", unit),
         x = "Fiscal Year",
         y = "FMRs") +
    scale_x_continuous(breaks = seq(2011, 2024, 1), limits = c(2011, 2024)) +
    scale_y_continuous(labels = scales::dollar) +
    scale_color_brewer(palette = "Dark2") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

create_plotly_scatter_plot <- function(unit) {
  # Subset data for the specified bedroom unit
  subset_data <- subset(combined_data, BedroomUnits == unit)
  
  # Create custom hover text
  hover_text <- paste("The FMRs was $", subset_data$FMRs, " for the Fiscal Year ", subset_data$Year, " in ", subset_data$`Statistical Area`, sep = "")
  
  # Create plotly scatter plot
  p <- plot_ly(data = subset_data, x = ~Year, y = ~FMRs, color = ~`Statistical Area`, type = 'scatter', mode = 'markers',
               text = hover_text, hoverinfo = "text") %>%
    layout(title = paste("Comparison of FMRs for", unit),
           xaxis = list(title = "Fiscal Year", tickmode = "linear", tick0 = 2011, dtick = 1),
           yaxis = list(title = "FMRs", tickformat = "$"))
  return(p)
}



# Create individual plot for each bedroom unit
for (unit in ordered_levels) {
  print(create_plotly_scatter_plot(unit))
}

```




```{r FMRs for Statistical Area - Clark vs. MSA continued}

calculate_percent_change <- function(df, column_names) {
  results_list <- list() # Initialize an empty list to store data frames
  
  for (col in column_names) {
    # Calculate percent change using dplyr's lag function
    df[[paste0(col, "_Percent_Change")]] <- (df[[col]] - dplyr::lag(df[[col]])) / dplyr::lag(df[[col]]) * 100
    
    # Create a new data frame with Year and Percent_Change
    percent_change_df <- df %>% 
      select(Year, paste0(col, "_Percent_Change")) %>%
      drop_na() # Use drop_na() to remove rows with NAs in the new percent change column

    # Store the data frame in the list with a unique name
    results_list[[col]] <- percent_change_df
  }
  
  return(results_list) # Return the list of data frames
}

# Apply the function to Clark County data frame excluding the Year column
clark_percent_changes <- calculate_percent_change(df_clark_avg, names(df_clark_avg)[-1])

# Apply the function to MSA data frame excluding the Year column
msa_percent_changes <- calculate_percent_change(df_msa, names(df_msa)[-1])

# Function to calculate percent change within each data frame
calculate_percent_change_for_bedroom_units <- function(df) {
  df %>% 
    group_by(BedroomUnits) %>%
    arrange(Year, .by_group = TRUE) %>%
    mutate(FMRs_Percent_Change = (FMRs - lag(FMRs)) / lag(FMRs) * 100) %>%
    ungroup() %>%
    select(-FMRs) %>%
    filter(!is.na(FMRs_Percent_Change))
}

# Apply the function to both Clark and MSA data frames
percent_change_clark <- calculate_percent_change_for_bedroom_units(BedroomUnits_clark)
percent_change_msa <- calculate_percent_change_for_bedroom_units(BedroomUnits_msa)

# Merge the two data frames based on Year and BedroomUnits
merged_percent_change <- merge(percent_change_clark, percent_change_msa, by = c("Year", "BedroomUnits"), suffixes = c("_clark", "_msa"))

# Display the merged data frame
head(merged_percent_change)


# Plotting FMR Percent Change over Years for Clark and MSA by Bedroom Units
ggplot(merged_percent_change, aes(x = Year, y = FMRs_Percent_Change_clark, group = BedroomUnits, color = BedroomUnits)) +
  geom_line() +
  geom_point() +
  facet_wrap(~BedroomUnits) +
  labs(title = "Yearly Percent Change in FMRs for Clark County by Bedroom Unit Type",
       y = "Percent Change in FMRs",
       color = "Bedroom Unit Type") +
  theme_minimal()



```



Data Engineering for per capita personal income in MSA and Clark County

```{r per capita personal income - Data Cleaning}

# Pull Portland-Vancouver-Hillsboro Data
API_MSA <- read_csv("Data/Annual Personal Income MSA.csv")

# Pull Clark County Data
API_Clark <- read_csv("Data/Annual Personal Income ClarkCounty.csv")

summary(API_MSA$Year)
summary(API_Clark$Year)

head(API_Clark)
head(API_MSA)

# Create the time series of API for Clark County
ggplot(data = API_MSA, aes(x = Year, y = `Per capita personal income (dollars)`)) +
  geom_line(color = "blue") +  # Line color
  geom_point(color = "red") +  # Point color
  labs(title = "Time Series Graph of Per Capita Personal Income",
       x = "Year",
       y = "Per Capita Personal Income (Dollars)") +
  theme_minimal()  # Theme of the plot

# Create the time series of API for Clark County
ggplot(data = API_Clark, aes(x = Year, y = `Per capita personal income (dollars)`)) +
  geom_line(color = "blue") +  # Line color
  geom_point(color = "red") +  # Point color
  labs(title = "Time Series Graph of Per Capita Personal Income",
       x = "Year",
       y = "Per Capita Personal Income (Dollars)") +
  theme_minimal()  # Theme of the plot

# Add a new variable to each dataset to indicate the Statistical Area
API_MSA <- API_MSA %>% mutate(Statistical_Area = "Portland-Vancouver-Hillsboro, OR-WA")
API_Clark <- API_Clark %>% mutate(Statistical_Area = "Clark County")

# Combine Data
combined_data2 <- bind_rows(
  select(API_MSA, Year, `Per capita personal income (dollars)`, Statistical_Area),
  select(API_Clark, Year, `Per capita personal income (dollars)`, Statistical_Area)
)

head(combined_data2)

# Create the time series graph for comparison
ggplot(data = combined_data2, aes(x = Year, y = `Per capita personal income (dollars)`, color = Statistical_Area, group = Statistical_Area)) +
  geom_line() +  # Line type
  geom_point() +  # Point type
  labs(title = "Comparison of Per Capita Personal Income",
       x = "Year",
       y = "Per Capita Personal Income (Dollars)") +
  theme_minimal() +  # Theme of the plot
  scale_color_manual(values = c("blue", "red"))  # Set manual colors for the lines

# Create the interactive time series graph for comparison
plot <- plot_ly(data = combined_data2, x = ~Year, y = ~`Per capita personal income (dollars)`, color = ~Statistical_Area, type = 'scatter', mode = 'lines+markers',
                text = ~paste("The personal income was $", `Per capita personal income (dollars)`, " for the Year ", Year, " in ", Statistical_Area, sep = ""),
                hoverinfo = "text") %>%
  layout(title = "Personal income in Clark County from 1969 to 2021",
         xaxis = list(title = "Year", dtick = 5),  # Set tick distance on x-axis
         yaxis = list(title = "Personal Income", tickprefix = "$", dtick = 10000, rangemode = "tozero"))  # Set tick distance and prefix on y-axis

# Show the plot
plot

```


```{r TEST}

# Filter the data for the years 2011-2021
filtered_data <- combined_data2 %>% 
  filter(Year >= 2011 & Year <= 2021)

# Create the time series graph for comparison
ggplot(data = filtered_data, aes(x = Year, y = `Per capita personal income (dollars)`, color = Statistical_Area, group = Statistical_Area)) +
  geom_line() +  # Line type
  geom_point() +  # Point type
  labs(title = "Comparison of Per Capita Personal Income (2011-2021)",
       x = "Year",
       y = "Per Capita Personal Income (Dollars)") +
  theme_minimal() +  # Theme of the plot
  scale_color_manual(values = c("blue", "red"))  # Set manual colors for the lines


```



```{r Descriptive Statistics for Per Capita Personal Income}

desc_stats_income_msa <- summary(API_MSA$`Per capita personal income (dollars)`)
desc_stats_income_clark <- summary(API_Clark$`Per capita personal income (dollars)`)

data.frame(
  Statistic = names(desc_stats_income_msa),
  MSA_Indicators = as.numeric(desc_stats_income_msa),
  Clark_Indicators = as.numeric(desc_stats_income_clark)
)

```


Data Engineering for Educational Attainment in Clark County

```{r Educational Attainment in Clark County - Data Cleaning}

# Pull Clark County Educational Attainment Data from ACS 2022 1-year
Ed_Index <- read_csv("Data/Educational Attainment.csv")
head(Ed_Index)

# Convert wide format to long format
Ed_Index_long <- Ed_Index %>%
  gather(key = "education_level", value = "value")

# Grouping educational levels based on categories
Ed_Index_long$education_group <- with(Ed_Index_long, case_when(
  education_level == "No schooling completed" ~ "No Formal Education",
  education_level %in% c("Nursery to 4th grade", "5th and 6th grade", "7th and 8th grade", 
                         "9th grade", "10th grade", "11th grade", "12th grade, no diploma") ~ "K-12 no diploma",
  education_level %in% c("Regular high school diploma", "GED or alternative credential") ~ "High School diploma, GED or alternative credential",
  education_level %in% c("Some college, less than 1 year", "Some college, 1 or more years, no degree", 
                         "Associate's degree") ~ "Some College or Associates Degree",
  education_level == "Bachelor's degree" ~ "Undergraduate",
  education_level %in% c("Master's degree", "Professional school degree", "Doctorate degree") ~ "Graduate",
  TRUE ~ as.character(education_level)
))

# Convert percentage values to numeric
Ed_Index_long$value <- as.numeric(gsub("%", "", Ed_Index_long$value))

# Aggregate values for each educational group
Ed_Index_aggregated <- Ed_Index_long %>%
  group_by(education_group) %>%
  summarise(total_value = sum(value, na.rm = TRUE))

# Display the aggregated data
Ed_Index_aggregated

ggplot(Ed_Index_aggregated, aes(x = education_group, y = total_value)) +
  geom_bar(stat = "identity") +
  coord_flip() +  # Flip coordinates for better visualization
  labs(title = "Educational Attainment Data from ACS 2022 1-year in Clark County, WA",
       x = "Educational Group",
       y = "Total Value") +
  theme_minimal()

# Define the order for the educational groups
education_order <- c("No Formal Education", "K-12 no diploma", "High School diploma, GED or alternative credential", "Some College or Associates Degree", "Undergraduate", "Graduate")

# Horizontal Bar Plot
ggplot(Ed_Index_aggregated, aes(x = factor(education_group, levels = education_order), y = total_value, fill = education_group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", total_value)), hjust = -0.3, size = 3.5) +  # Adjusted hjust for better text positioning
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  coord_flip() +
  labs(title = "Educational Attainment Data from ACS 2022 1-year in Clark County, WA",
       x = "",
       y = "Percent Completed") +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0))

# Vertical Bar Plot
ggplot(Ed_Index_aggregated, aes(x = factor(education_group, levels = education_order), y = total_value, fill = education_group)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", total_value)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  labs(title = "2022 Educational Attainment in Clark County, WA",
       x = "",
       y = "Percent Completed") +
  theme_minimal() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),  # Made text bold
        plot.title = element_text(hjust = 0))


```


I am going to group the education levels into the following categories:

No Formal Education: 
No schooling completed

K-12 no diploma:
Nursery to 4th grade
5th and 6th grade
7th and 8th grade
9th grade
10th grade
11th grade
12th grade, no diploma

High School diploma, GED or alternative credential:
Regular high school diploma
GED or alternative credential

Some College or Associates Degree:
Some college, less than 1 year
Some college, 1 or more years, no degree
Associate's degree

Undergraduate:
Bachelor's degree

Graduate:
Master's degree
Professional school degree
Doctorate degree


## Data Engineering for SNAP by Poverty Status for Households in Clark County

```{r SNAP by Poverty Status for Households - Data Cleaning}

# SNAP in the Past 12 Months by Poverty Status in the Past 12 Months for Households
# Pull Clark County SNAP by Poverty Status for Households Data from ACS 2022 1-year
SNAP_Index <- read_csv("Data/SNAPbyPovertyClark.csv")
head(SNAP_Index)

# Rename the columns
colnames(SNAP_Index) <- c("SNAP recipients and Income below poverty level",
                          "SNAP recipient and Income at or above poverty level",
                          "Income below poverty level and no SNAP",
                          "Income at or above poverty level and no SNAP")

# Convert the data to long format for visualization
SNAP_long <- tidyr::gather(SNAP_Index, key = "Category", value = "Percentage")

# Convert the Percentage column to numeric
SNAP_long$Percentage <- as.numeric(gsub("%", "", SNAP_long$Percentage))

# Convert columns to numeric
SNAP_Index$`SNAP recipients and Income below poverty level` <- as.numeric(gsub("%", "", SNAP_Index$`SNAP recipients and Income below poverty level`))
SNAP_Index$`SNAP recipient and Income at or above poverty level` <- as.numeric(gsub("%", "", SNAP_Index$`SNAP recipient and Income at or above poverty level`))
SNAP_Index$`Income below poverty level and no SNAP` <- as.numeric(gsub("%", "", SNAP_Index$`Income below poverty level and no SNAP`))
SNAP_Index$`Income at or above poverty level and no SNAP` <- as.numeric(gsub("%", "", SNAP_Index$`Income at or above poverty level and no SNAP`))

# Convert the data to long format for visualization
SNAP_long <- tidyr::gather(SNAP_Index, key = "Category", value = "Percentage")

# Aggregate the data
SNAP_aggregated <- SNAP_Index %>%
  summarise(
    `SNAP Recipients` = `SNAP recipients and Income below poverty level` + `SNAP recipient and Income at or above poverty level`,
    `Income below poverty level and no SNAP` = `Income below poverty level and no SNAP`,
    `Income at or above poverty level and no SNAP` = `Income at or above poverty level and no SNAP`
  )

# Convert the data to long format for visualization
SNAP_long_aggregated <- tidyr::gather(SNAP_aggregated, key = "Category", value = "Percentage")

# Bar Plot
ggplot(SNAP_long_aggregated, aes(x = Category, y = Percentage, fill = Category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", Percentage)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Add % to y-axis values
  labs(title = "Comparison of SNAP Recipients vs. Non-Recipients in Clark County, WA (ACS 2022 1-year)",
       x = "",
       y = "Percentage of Households") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

# Bar Plot
ggplot(SNAP_long, aes(x = Category, y = Percentage, fill = Category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", Percentage)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  # Add % to y-axis values
  labs(title = "SNAP Receipt by Poverty Status in Clark County, WA (ACS 2022 1-year)",
       x = "",
       y = "Percentage of Households") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

```


Data Engineering for Vacancy Status in Clark County

```{r Vacancy Status - Data Cleaning}

# Pull Clark County Vacancy Status Data from ACS 2022 1-year
Vacan_Index <- read_csv("Data/VacancyStatusClark.csv")
head(Vacan_Index)

# Convert the data to long format for visualization
vacancy_long <- tidyr::gather(Vacan_Index, key = "Vacancy_Status", value = "Percentage")

# Filter out the "For migrant workers" category
vacancy_long <- vacancy_long %>% filter(Vacancy_Status != "For migrant workers" | Percentage > 0)

# Bar Plot
ggplot(vacancy_long, aes(x = Vacancy_Status, y = as.numeric(gsub("%", "", Percentage)), fill = Vacancy_Status)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Percentage), vjust = -0.5, size = 3.5) +
  labs(title = "Vacancy Status Distribution in Clark County",
       x = "",
       y = "Percentage of Properties") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

# Extract relevant columns
rental_data <- Vacan_Index[, c("For rent", "Rented, not occupied")]

# Bar plot to visualize the distribution
rental_df <- data.frame(
  Category = c("For Rent", "Rented, Not Occupied"),
  Percentage = as.numeric(gsub("%", "", unlist(rental_data)))
)

# Adjust the "For rent" percentage
Vacan_Index$`For rent` <- as.numeric(gsub("%", "", Vacan_Index$`For rent`)) - as.numeric(gsub("%", "", Vacan_Index$`For sale only`))

# Efficiency Analysis:
efficiency_data <- Vacan_Index[, c("For rent", "Rented, not occupied")]

# Convert data to long format for visualization
efficiency_long <- tidyr::gather(efficiency_data, key = "Efficiency_Type", value = "Percentage")

# Bar plot for Efficiency Analysis
ggplot(efficiency_long, aes(x = Efficiency_Type, y = as.numeric(gsub("%", "", Percentage)), fill = Efficiency_Type)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = sprintf("%.2f%%", as.numeric(gsub("%", "", Percentage)))), vjust = -0.5, size = 3.5) +
  labs(title = "Efficiency Analysis",
       x = "",
       y = "Percentage of Units") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

# Efficiency Analysis
efficiency_data <- Vacan_Index[, c("For rent", "Rented, not occupied", "For sale only", "Sold, not occupied")]

# Convert data to long format for visualization
efficiency_long <- tidyr::gather(efficiency_data, key = "Efficiency_Type", value = "Percentage")

# Order the Efficiency_Type factor as per the desired order
efficiency_long$Efficiency_Type <- factor(efficiency_long$Efficiency_Type, 
                                          levels = c("For rent", "Rented, not occupied", "For sale only", "Sold, not occupied"))

# Bar plot for Efficiency Analysis
ggplot(efficiency_long, aes(x = Efficiency_Type, y = as.numeric(gsub("%", "", Percentage)), fill = Efficiency_Type)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Percentage), vjust = -0.5, size = 3.5) +
  labs(title = "Efficiency Analysis",
       x = "",
       y = "Percentage of Units") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")


```



Data Engineering Vacancy Status by Zip

```{r Vacancy Status by Zip - Data Cleaning}

# Pull Geospatial Data shp and shx
Vacan_shapefile <- st_read("Data/VacancyStatusZip.shp")

plot(Vacan_shapefile)
column_names <- names(Vacan_shapefile)

# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(Vacan_shapefile)[grepl("e$", names(Vacan_shapefile)) & names(Vacan_shapefile) != "name"]

# Remove the identified columns
Vacan_shapefile <- Vacan_shapefile[, !names(Vacan_shapefile) %in% columns_to_remove]

# Inspect the modified data
plot(Vacan_shapefile)

# Save the modified shapefile `st_write(Vacan_shapefile, "Data/ModifiedVacancyStatusZip.shp")`

# Transform data to percents
# Identify columns to calculate percentage for, exclude columns like "geoid", "name", and "B25004001" 
# Get the name of the geometry column
geom_col_name <- attr(Vacan_shapefile, "sf_column")
# Exclude the geometry column  when identifying columns for percentage calculation
columns_to_calculate <- setdiff(names(Vacan_shapefile), c("geoid", "name", "B25004001", geom_col_name))

# Calculate and round percentage for each column
for (col in columns_to_calculate) {
  if (is.numeric(Vacan_shapefile[[col]]) && is.numeric(Vacan_shapefile$B25004001)) {
    new_col_name <- paste0(col, "_pct")
    percentage_values <- (Vacan_shapefile[[col]] / Vacan_shapefile$B25004001) * 100
    Vacan_shapefile[[new_col_name]] <- as.numeric(round(percentage_values, 1))
  } else {
    cat(paste("Skipping non-numeric column:", col, "\n"))
  }
}

# Create a named vector for column renaming
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B25004001" = "Total",
  "B25004002" = "For rent",
  "B25004003" = "Rented, not occupied",
  "B25004004" = "For sale only",
  "B25004005" = "Sold, not occupied",
  "B25004006" = "For seasonal, recreational, or occasional use",
  "B25004007" = "For migrant workers",
  "B25004008" = "Other vacant"
)

# Rename the percentage columns
pct_columns <- paste0(columns_to_calculate, "_pct")
old_pct_names <- pct_columns
new_pct_names <- column_mapping[columns_to_calculate]

names(Vacan_shapefile)[names(Vacan_shapefile) %in% old_pct_names] <- new_pct_names

# Print a message indicating successful renaming and display the names of the renamed columns
cat("Percentage columns renamed successfully:\n")
for (i in 1:length(old_pct_names)) {
  cat(paste(old_pct_names[i], "=>", new_pct_names[i], "\n"))
}

tm_shape(Vacan_shapefile) + 
  tm_borders() + 
  tm_fill("For rent", title = "For Rent Properties")

# Create the graph
tm_shape(Vacan_shapefile) + 
  tm_borders() + 
  tm_fill(col = "For rent", 
          palette = "-viridis", 
          title = "For rent (%)",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

# Create the hover text column using the cleaned CleanedGeoid column
Vacan_shapefile$hover_text <- paste0(
  (Vacan_shapefile$name),
  " is at ",
  round(Vacan_shapefile$`For rent`, 1),
  "%"
)

# Convert the sf object to a Spatial object for compatibility with leaflet
Vacan_sp <- as(Vacan_shapefile, "Spatial")

# For Rent
leaflet(Vacan_sp) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addPolygons(
    fillColor = ~colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 50))(Vacan_shapefile$`For rent`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.5,
    highlight = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE
    ),
    label = ~hover_text,
    labelOptions = labelOptions(
      style = list("font-weight" = "bold"),
      textsize = "15px",
      direction = "auto"
    )
  ) %>%
  addLegend(
    pal = colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 50)),
    values = Vacan_shapefile$`For rent`,
    opacity = 0.7,
    title = "Units for rent by ZIP Code (%)",
    position = "bottomright",
    labFormat = labelFormat(suffix = "%")
  )

# Create the hover text column for "Rented, not occupied"
Vacan_shapefile$hover_text_rented <- paste0(
  (Vacan_shapefile$name),
  " has ",
  round(Vacan_shapefile$`Rented, not occupied`, 1),
  "% of units that are rented but not occupied."
)

# Create the hover text column for "For sale only"
Vacan_shapefile$hover_text_sale <- paste0(
  (Vacan_shapefile$name),
  " has ",
  round(Vacan_shapefile$`For sale only`, 1),
  "% of units that are for sale only."
)

# Convert the sf object to a Spatial object for compatibility with leaflet
Vacan_sp <- as(Vacan_shapefile, "Spatial")


# Plot for "Rented, not occupied"
leaflet(Vacan_sp) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addPolygons(
    fillColor = ~colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 50))(Vacan_shapefile$`Rented, not occupied`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.5,
    highlight = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE
    ),
    label = ~hover_text_rented,
    labelOptions = labelOptions(
      style = list("font-weight" = "bold"),
      textsize = "15px",
      direction = "auto"
    )
  ) %>%
  addLegend(
    pal = colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 15)),
    values = Vacan_shapefile$`Rented, not occupied`,
    opacity = 0.7,
    title = "Units rented but not occupied by ZIP Code (%)",
    position = "bottomright",
    labFormat = labelFormat(suffix = "%")
  )

# Create the hover text column for "For sale only"
Vacan_shapefile$hover_text_sale <- paste0(
  (Vacan_shapefile$name),
  " has ",
  round(Vacan_shapefile$`For sale only`, 1),
  "% of units that are for sale only."
)

# Plot for "For sale only"
leaflet(Vacan_sp) %>%
  addProviderTiles(providers$OpenStreetMap) %>%
  addPolygons(
    fillColor = ~colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 50))(Vacan_shapefile$`For sale only`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.5,
    highlight = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE
    ),
    label = ~hover_text_sale,
    labelOptions = labelOptions(
      style = list("font-weight" = "bold"),
      textsize = "15px",
      direction = "auto"
    )
  ) %>%
  addLegend(
    pal = colorNumeric(palette = viridis(100, direction = -1), domain = c(0, 40)),
    values = Vacan_shapefile$`For sale only`,
    opacity = 0.7,
    title = "Units for sale only by ZIP Code (%)",
    position = "bottomright",
    labFormat = labelFormat(suffix = "%")
  )


```


Data Engineering for SNAP by Poverty Status for Households by Zip

```{r SNAP by Poverty Status by Zip - Data Cleaning}

# Pull SNAP by Poverty Status Data by Zip from ACS 2021 5-year
SNAP_shapefile <- st_read("Data/SNAPbyPovertyZip.shp")
column_names <- names(SNAP_shapefile)

# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(SNAP_shapefile)[grepl("e$", names(SNAP_shapefile)) & names(SNAP_shapefile) != "name"]

# Remove the identified columns
SNAP_shapefile <- SNAP_shapefile[, !names(SNAP_shapefile) %in% columns_to_remove]

# Inspect the modified data
plot(SNAP_shapefile)

# Save the modified shapefile `st_write(SNAP_shapefile, "Data/ModifiedVacancyStatusZip.shp")`

# Transform data to percents
# Identify columns to calculate percentage for, exclude columns like "geoid", "name", and "B22003001" 
# Get the name of the geometry column
geom_col_name <- attr(SNAP_shapefile, "sf_column")
# Exclude the geometry column  when identifying columns for percentage calculation
columns_to_calculate <- setdiff(names(SNAP_shapefile), c("geoid", "name", "B22003001", geom_col_name))

# Calculate and round percentage for each column
for (col in columns_to_calculate) {
  if (is.numeric(SNAP_shapefile[[col]]) && is.numeric(SNAP_shapefile$B22003001)) {
    new_col_name <- paste0(col, "_pct")
    percentage_values <- (SNAP_shapefile[[col]] / SNAP_shapefile$B22003001) * 100
    SNAP_shapefile[[new_col_name]] <- as.numeric(round(percentage_values, 1))
  } else {
    cat(paste("Skipping non-numeric column:", col, "\n"))
  }
}

# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B22003001" = "Total",
  "B22003002" = "Household received SNAP",
  "B22003003" = "Income below poverty level and received SNAP",
  "B22003004" = "Income at or above poverty level",
  "B22003005" = "Household did not receive SNAP",
  "B22003006" = "Income below poverty level and did not receive SNAP",
  "B22003007" = "Income at or above poverty level"
)

# Rename the percentage columns
pct_columns <- paste0(columns_to_calculate, "_pct")
old_pct_names <- pct_columns
new_pct_names <- column_mapping[columns_to_calculate]

names(SNAP_shapefile)[names(SNAP_shapefile) %in% old_pct_names] <- new_pct_names

# Print a message indicating successful renaming and display the names of the renamed columns
cat("Percentage columns renamed successfully:\n")
for (i in 1:length(old_pct_names)) {
  cat(paste(old_pct_names[i], "=>", new_pct_names[i], "\n"))
}

tm_shape(SNAP_shapefile) + 
  tm_borders() + 
  tm_fill("Household received SNAP")

# Create the graph
tm_shape(SNAP_shapefile) + 
  tm_borders() + 
  tm_fill(col = "Income below poverty level and did not receive SNAP", 
          palette = "-viridis", 
          title = "Income below poverty level and did not receive SNAP (%)",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

# Remove rows where the name is "Clark County, WA"
SNAP_shapefile <- SNAP_shapefile[SNAP_shapefile$name != "Clark County, WA", ]

# Function to create an interactive map for a specified column
create_map <- function(data, column_name) {
  
  # Create hover text for the specified column
  hover_text <- paste0(data$name, " has ", round(data[[column_name]], 1), "%")
  
  # Define the color map
  color_map <- colorNumeric(palette = viridis(100, direction = -1), domain = range(data[[column_name]], na.rm = TRUE))
  
  # Convert the sf object to a Spatial object for compatibility with leaflet
  data_sp <- as(data, "Spatial")
  
  # Create the map
  leaflet(data_sp) %>%
    addProviderTiles(providers$OpenStreetMap) %>%
    addPolygons(
      fillColor = ~color_map(data[[column_name]]),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.5,
      highlight = highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.7,
        bringToFront = TRUE
      ),
      label = ~hover_text,
      labelOptions = labelOptions(
        style = list("font-weight" = "bold"),
        textsize = "15px",
        direction = "auto"
      )
    ) %>%
    addLegend(
      pal = color_map,
      values = data[[column_name]],
      opacity = 0.7,
      title = paste(column_name, "by ZIP Code (%)"),
      position = "bottomright",
      labFormat = labelFormat(suffix = "%")
    )
}

# Create maps for the specified columns
create_map(SNAP_shapefile, "Household received SNAP")
create_map(SNAP_shapefile, "Income below poverty level and received SNAP")
create_map(SNAP_shapefile, "Income below poverty level and did not receive SNAP")

```


Data Engineering for Employment Status by Zip

```{r Employment Status by Zip - Data Cleaning}

# Pull Employment Status Data by Zip from ACS 2021 5-year
# Pull Geospatial Data shp and shx
Employment_shapefile <- st_read("Data/EmploymentZip.shp")

plot(Employment_shapefile)
column_names <- names(Employment_shapefile)

# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(Employment_shapefile)[grepl("e$", names(Employment_shapefile)) & names(Employment_shapefile) != "name"]

# Remove the identified columns
Employment_shapefile <- Employment_shapefile[, !names(Employment_shapefile) %in% columns_to_remove]

# Inspect the modified data
plot(Employment_shapefile)

# st_write(Employment_shapefile, "Data/ModifiedEmploymentZip.shp")

# Transform data to percents
# Identify columns to calculate percentage for, exclude columns like "geoid", "name", and "B23025001" 
# Get the name of the geometry column
geom_col_name <- attr(Employment_shapefile, "sf_column")
# Exclude the geometry column  when identifying columns for percentage calculation
columns_to_calculate <- setdiff(names(Employment_shapefile), c("geoid", "name", "B23025001", geom_col_name))

# Calculate and round percentage for each column
for (col in columns_to_calculate) {
  if (is.numeric(Employment_shapefile[[col]]) && is.numeric(Employment_shapefile$B23025001)) {
    new_col_name <- paste0(col, "_pct")
    percentage_values <- (Employment_shapefile[[col]] / Employment_shapefile$B23025001) * 100
    Employment_shapefile[[new_col_name]] <- as.numeric(round(percentage_values, 1))
  } else {
    cat(paste("Skipping non-numeric column:", col, "\n"))
  }
}

# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B23025001" = "Total",
  "B23025002" = "In labor force",
  "B23025003" = "Civilian labor force",
  "B23025004" = "Employed",
  "B23025005" = "Unemployed",
  "B23025006" = "Armed Forces",
  "B23025007" = "Not in labor force"
)
# Rename the percentage columns
pct_columns <- paste0(columns_to_calculate, "_pct")
old_pct_names <- pct_columns
new_pct_names <- column_mapping[columns_to_calculate]

names(Employment_shapefile)[names(Employment_shapefile) %in% old_pct_names] <- new_pct_names

# Print a message indicating successful renaming and display the names of the renamed columns
cat("Percentage columns renamed successfully:\n")
for (i in 1:length(old_pct_names)) {
  cat(paste(old_pct_names[i], "=>", new_pct_names[i], "\n"))
}

tm_shape(Employment_shapefile) + 
  tm_borders() + 
  tm_fill("Employed")

# Create the graph
tm_shape(Employment_shapefile) + 
  tm_borders() + 
  tm_fill(col = "Unemployed", 
          palette = "-viridis", 
          title = "Unemployed (%)",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

# Define a function to create a leaflet map for a given column
create_map <- function(data, column_name) {
  # Define the color palette
  color_map <- colorNumeric(palette = viridis(100, direction = -1), domain = data[[column_name]], na.color = "transparent")
  
  # Create hover text
  data$hover_text <- paste0(data$name, " has ", round(data[[column_name]], 1), "%")
  
  # Create the leaflet map
  leaflet(data) %>%
    addProviderTiles(providers$OpenStreetMap) %>%
    addPolygons(
      fillColor = ~color_map(data[[column_name]]),
      weight = 2,
      opacity = 1,
      color = "white",
      dashArray = "3",
      fillOpacity = 0.7,
      highlight = highlightOptions(
        weight = 5,
        color = "#666",
        dashArray = "",
        fillOpacity = 0.9,
        bringToFront = TRUE
      ),
      label = ~hover_text,
      labelOptions = labelOptions(
        style = list("font-weight" = "bold"),
        textsize = "15px",
        direction = "auto"
      )
    ) %>%
    addLegend(
      pal = color_map,
      values = data[[column_name]],
      opacity = 0.7,
      title = column_name,
      position = "bottomright",
      labFormat = labelFormat(suffix = "%")
    )
}

# Create maps for the specified columns
create_map(Employment_shapefile, "Employed")
create_map(Employment_shapefile, "Unemployed")
create_map(Employment_shapefile, "Not in labor force")

```

Data Engineering for Hispanic or Latino Origin by Race by Zip

```{r Hispanic or Latino Origin by Race by Zip - Data Cleaning}

# Pull Hispanic or Latino Origin by Race Data by Zip from ACS 2021 5-year
Race_shapefile <- st_read("Data/RaceEthnZip.shp")
head(Race_shapefile)

plot(Race_shapefile)
column_names <- names(Race_shapefile)

# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(Race_shapefile)[grepl("e$", names(Race_shapefile)) & names(Race_shapefile) != "name"]

# Remove the identified columns
Race_shapefile <- Race_shapefile[, !names(Race_shapefile) %in% columns_to_remove]

# Inspect the modified data
plot(Race_shapefile)

# st_write(Race_shapefile, "Data/ModifiedRaceEthnZip.shp")

# Transform data to percents
# Identify columns to calculate percentage for, exclude columns like "geoid", "name", and "B03002001" 
# Get the name of the geometry column
geom_col_name <- attr(Race_shapefile, "sf_column")
# Exclude the geometry column  when identifying columns for percentage calculation
columns_to_calculate <- setdiff(names(Race_shapefile), c("geoid", "name", "B03002001", geom_col_name))

# Calculate and round percentage for each column
for (col in columns_to_calculate) {
  if (is.numeric(Race_shapefile[[col]]) && is.numeric(Race_shapefile$B03002001)) {
    new_col_name <- paste0(col, "_pct")
    percentage_values <- (Race_shapefile[[col]] / Race_shapefile$B03002001) * 100
    Race_shapefile[[new_col_name]] <- as.numeric(round(percentage_values, 1))
  } else {
    cat(paste("Skipping non-numeric column:", col, "\n"))
  }
}

# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B03002001" = "Total",
  "B03002002" = "Not Hispanic or Latino",
  "B03002003" = "White alone",
  "B03002004" = "Black or African American alone",
  "B03002005" = "American Indian and Alaska Native alone",
  "B03002006" = "Asian alone",
  "B03002007" = "Native Hawaiian and Other Pacific Islander alone",
  "B03002008" = "Some other race alone",
  "B03002009" = "Two or more races",
  "B03002010" = "Two races including Some other race",
  "B03002011" = "Two races excluding Some other race, and three or more races",
  "B03002012" = "Hispanic or Latino")

# Rename the percentage columns
pct_columns <- paste0(columns_to_calculate, "_pct")
old_pct_names <- pct_columns
new_pct_names <- column_mapping[columns_to_calculate]

names(Race_shapefile)[names(Race_shapefile) %in% old_pct_names] <- new_pct_names

# Print a message indicating successful renaming and display the names of the renamed columns
cat("Percentage columns renamed successfully:\n")
for (i in 1:length(old_pct_names)) {
  cat(paste(old_pct_names[i], "=>", new_pct_names[i], "\n"))
}

tm_shape(Race_shapefile) + 
  tm_borders() + 
  tm_fill("Hispanic or Latino", title = "Hispanic or Latino")

# Create the 'White Alone' group
Race_shapefile$White_Alone <- Race_shapefile$`White alone`

# Create the 'People of Color' group
Race_shapefile$People_of_Color <- Race_shapefile$`Black or African American alone` +
                                 Race_shapefile$`American Indian and Alaska Native alone` +
                                 Race_shapefile$`Asian alone` +
                                 Race_shapefile$`Native Hawaiian and Other Pacific Islander alone` +
                                 Race_shapefile$`Some other race alone` +
                                 Race_shapefile$`Two or more races` +
                                 Race_shapefile$`Hispanic or Latino`

# Inspect the first few rows of the modified data
head(Race_shapefile[, c("White_Alone", "People_of_Color")])

# Assuming you've already read in the shapefile and performed the data cleaning and transformation
# Race_shapefile <- st_read("path_to_your_shapefile.shp")

# Create the graph
tm_shape(Race_shapefile) + 
  tm_borders() + 
  tm_fill(col = "People_of_Color", 
          palette = "-viridis", 
          title = "People of Color (%)",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

```

Data Engineering for Median Household Income by Zip

```{r Median Household Income by Zip - Data Cleaning}

# Pull Median Household Income by Zip from ACS 2021 5-year
Income_shapefile <- st_read("Data/MedianIncomeZip.shp")
head(Income_shapefile)

plot(Income_shapefile)
column_names <- names(Income_shapefile)

# I need to remove all labels that end with `e` as this is a duplicate value with a processing error
# Identify columns ending with 'e' but exclude the "name" column
columns_to_remove <- names(Income_shapefile)[grepl("e$", names(Income_shapefile)) & names(Income_shapefile) != "name"]

# Remove the identified columns
Income_shapefile <- Income_shapefile[, !names(Income_shapefile) %in% columns_to_remove]

# Inspect the modified data
plot(Income_shapefile)

# st_write(Income_shapefile, "Data/ModifiedMedianIncomeZip.shp")

# Rename columns
column_mapping <- c(
  "geoid" = "geoid",
  "name" = "Zip",
  "B19013001" = "Median household income"
)

# Get the name of the geometry column
geom_col_name <- attr(Income_shapefile, "sf_column")

# Exclude the geometry column when renaming
columns_to_rename <- setdiff(names(Income_shapefile), geom_col_name)

# Correctly apply the column_mapping to rename the columns
names(Income_shapefile)[names(Income_shapefile) %in% names(column_mapping)] <- column_mapping[names(column_mapping)]

# Verify the renamed columns
head(names(Income_shapefile))


tm_shape(Income_shapefile) + 
  tm_borders() + 
  tm_fill("Median household income", title = "Median household income")

# Create the graph
tm_shape(Income_shapefile) + 
  tm_borders() + 
  tm_fill(col = "Median household income", 
          palette = "-viridis", 
          title = "Median household income",
          style = "quantile") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position = "right", 
            legend.title.size = 1.2,
            legend.text.size = 1)

```


```{r Rent prices by zip analysis}

# Pull Data and Clark County Shapefile (https://hub-clarkcountywa.opendata.arcgis.com/pages/digital-gis-data-download)
shapefile <- st_read("Data/Zipcode.shp")

# Transform data to long format
BedroomUnits_Zip <- tidyr::gather(df_clark_zip, BedroomUnits, "Rent", -Year, -ZIP)

# merge shapefile into long data
merged_data <- left_join(shapefile, BedroomUnits_Zip, by = c("ZIPCODE" = "ZIP"))

# Filter data for a specific Bedroom Unit and Year (e.g., "Efficiency" and 2023)
selected_data <- subset(merged_data, Year == 2023)
# transform your data to the WGS 84 CRS
selected_data <- st_transform(selected_data, 4326)

# Get unique values of BedroomUnits and Years
unique_bedroom_units <- unique(selected_data$BedroomUnits)
unique_years <- unique(selected_data$Year)

# Create maps for each combination of BedroomUnits and Year
for(bedroom in unique_bedroom_units) {
  for(year in unique_years) {
    # Filter data for the specific Bedroom Unit and Year
    sub_data <- subset(selected_data, BedroomUnits == bedroom & Year == year)
    
    # Generate the map
    map <- create_rent_map(sub_data, "Rent")
    
    # You can display the map here, or store it for later use
    print(map)
  }
}



```

















Zip Code Analysis

```{r Zip Code Analysis - Tertiles}

# Income Group
# Categorize 'Median household income' into tertiles
Income_shapefile <- Income_shapefile %>%
  mutate(income_tertile = ntile(`Median household income`, 3)) %>%
  mutate(income_category = case_when(
    income_tertile == 1 ~ "Low",
    income_tertile == 2 ~ "Medium",
    income_tertile == 3 ~ "High"
  ))


# BIPOC Group
# Remove columns with NA names
Race_shapefile <- Race_shapefile[, !is.na(names(Race_shapefile))]

# Alternatively, you can replace NA names with a new name, like so:
names(Race_shapefile)[which(is.na(names(Race_shapefile)))] <- paste0("NA_Column_", seq_along(which(is.na(names(Race_shapefile)))))

# Now, let's assume you want to create a 'People_of_Color' column, which seems to be a calculated field
# If 'People_of_Color' is not already a column, you may need to create it by summing all relevant columns of race/ethnicity other than 'White alone'
# Create the 'People of Color' group
Race_shapefile$People_of_Color <- Race_shapefile$`Black or African American alone` +
                                 Race_shapefile$`American Indian and Alaska Native alone` +
                                 Race_shapefile$`Asian alone` +
                                 Race_shapefile$`Native Hawaiian and Other Pacific Islander alone` +
                                 Race_shapefile$`Some other race alone` +
                                 Race_shapefile$`Two or more races` +
                                 Race_shapefile$`Hispanic or Latino`

# Check the structure of your data to ensure the 'People_of_Color' column is correct
str(Race_shapefile)

# Categorize 'People of Color' into tertiles
Race_shapefile <- Race_shapefile %>%
  mutate(BIPOC_tertile = ntile(`People_of_Color`, 3)) %>%
  mutate(BIPOC_category = case_when(
    BIPOC_tertile == 1 ~ "Low",
    BIPOC_tertile == 2 ~ "Medium",
    BIPOC_tertile == 3 ~ "High"
  ))

#Employment Group
# Unemployment
Employment_shapefile <- Employment_shapefile %>%
  mutate(Employment_tertile = ntile(`Unemployed`, 3)) %>%
  mutate(Employment_category = case_when(
    Employment_tertile == 1 ~ "Low",
    Employment_tertile == 2 ~ "Medium",
    Employment_tertile == 3 ~ "High"
  ))

# Food stamps Group
# SNAP
# Check for duplicate column names first
names(SNAP_shapefile) <- make.unique(names(SNAP_shapefile))
# Calculate tertiles for 'Household received SNAP'
SNAP_shapefile <- SNAP_shapefile %>%
  mutate(SNAP_tertile = ntile(`Household received SNAP`, 3)) %>%
  mutate(SNAP_category = case_when(
    SNAP_tertile == 1 ~ "Low",
    SNAP_tertile == 2 ~ "Medium",
    SNAP_tertile == 3 ~ "High"
  ))


# Vacancy Group
# Rent Vacancy
Vacan_shapefile <- Vacan_shapefile %>%
  mutate(RentVacan_tertile = ntile(`For rent`, 3)) %>%
  mutate(RentVacan_category = case_when(
    RentVacan_tertile == 1 ~ "Low",
    RentVacan_tertile == 2 ~ "Medium",
    RentVacan_tertile == 3 ~ "High"
  ))

# Convert to dataframe
Income_dataframe <- as.data.frame(Income_shapefile)
Race_dataframe <- as.data.frame(Race_shapefile)
Employment_dataframe <- as.data.frame(Employment_shapefile)
SNAP_dataframe <- as.data.frame(SNAP_shapefile)
Vacan_dataframe <- as.data.frame(Vacan_shapefile)


head(Income_dataframe)
head(Race_dataframe)
head(Employment_dataframe)
head(SNAP_dataframe)
head(Vacan_dataframe)

# Read the shapefile (if not already read)
shapefile <- st_read("Data/Zipcode.shp")

# Transform data to long format to have 'BedroomUnits' and 'Rent' as separate columns
BedroomUnits_Zip <- tidyr::gather(df_clark_zip, BedroomUnits, Rent, -Year, -ZIP)

# Merge the shapefile with the BedroomUnits_Zip dataframe
merged_data <- left_join(shapefile, BedroomUnits_Zip, by = c("ZIPCODE" = "ZIP"))

# Filter data for the year 2023
# selected_data <- subset(merged_data, Year == 2023)

#selected_data <- subset(merged_data)
# Transform your data to the WGS 84 CRS
selected_data <- st_transform(selected_data, 4326)


# Check the resulting dataframe
Rent_dataframe <- as.data.frame(selected_data)
head(Rent_dataframe)

```



Income Shapefile Categorization: You've categorized the median household income into tertiles correctly. Ensure that Income_shapefile has been properly loaded and contains the Median household income field.

Race Shapefile Cleaning and Categorization: You've managed to clean the column names for NA values in Race_shapefile and created a People_of_Color column by summing various racial demographics fields, which is an appropriate approach if those fields are mutually exclusive and collectively exhaustive of the BIPOC category.

Employment Shapefile Categorization: You're categorizing unemployment data into tertiles. Make sure Employment_shapefile is prepared with a specific column named Unemployed that you intend to use for this analysis.

SNAP Shapefile Categorization: Before calculating tertiles for households that received SNAP, you've correctly addressed the potential issue of duplicate names using make.unique.

Vacancy Shapefile Categorization: You've applied the tertile categorization to the For rent column in Vacan_shapefile.



```{r Zip Code Analysis - Tertiles Merge All Data}

# Rename the ZIP ID columns to 'Zip' for standardization
Rent_dataframe <- rename(Rent_dataframe, Zip = ZIPCODE)
Race_dataframe <- rename(Race_dataframe, Zip = name)
Employment_dataframe <- rename(Employment_dataframe, Zip = name)
SNAP_dataframe <- rename(SNAP_dataframe, Zip = name)
Vacan_dataframe <- rename(Vacan_dataframe, Zip = name)

# Convert the ZIP code column in the shapefile to character if it's numeric
shapefile$ZIPCODE <- as.character(shapefile$ZIPCODE)
# Convert the 'Zip' columns to characters for all dataframes
Rent_dataframe$Zip <- as.character(Rent_dataframe$Zip)
Income_dataframe$Zip <- as.character(Income_dataframe$Zip)
Race_dataframe$Zip <- as.character(Race_dataframe$Zip)
Employment_dataframe$Zip <- as.character(Employment_dataframe$Zip)
SNAP_dataframe$Zip <- as.character(SNAP_dataframe$Zip)
Vacan_dataframe$Zip <- as.character(Vacan_dataframe$Zip)

# Perform the spatial join
all_data_sf <- shapefile %>%
  left_join(Rent_dataframe, by = c("ZIPCODE" = "Zip")) %>%
  left_join(Income_dataframe, by = c("ZIPCODE" = "Zip")) %>%
  left_join(Race_dataframe, by = c("ZIPCODE" = "Zip")) %>%
  left_join(Employment_dataframe, by = c("ZIPCODE" = "Zip")) %>%
  left_join(SNAP_dataframe, by = c("ZIPCODE" = "Zip")) %>%
  left_join(Vacan_dataframe, by = c("ZIPCODE" = "Zip"))



```





```{r write data into file}

# Write to a GeoPackage for spatial data
# st_write(Rent_data_sf, "Data/all_data_sf.gpkg", layer = "spatial_layer", delete_layer = TRUE)
# CSV file
# write.csv(all_data_sf, "Data/all_data_sf.csv", row.names = FALSE)

```




```{r Model 1 - Zip Analysis}

# Create a spatial weights matrix
neighbors <- poly2nb(all_data_sf)
weights <- nb2listw(neighbors, style = "W")

# Calculate global Moran's I for 'income_tertile'
income_moran <- moran.test(all_data_sf$income_tertile, weights)
print(income_moran)
moran_test_BIPOC <- moran.test(all_data_sf$BIPOC_tertile, weights)
print(moran_test_BIPOC)
moran_test_rent <- moran.test(all_data_sf$Rent, weights)
print(moran_test_rent)
SNAP_moran <- moran.test(all_data_sf$SNAP_tertile, weights)
print(SNAP_moran)
unemployment_moran <- moran.test(all_data_sf$Employment_tertile, weights)
print(unemployment_moran)
vacancy_moran <- moran.test(all_data_sf$RentVacan_tertile, weights)
print(vacancy_moran)

# Initialize an empty list to store graphs
rent_graphs <- list()

# Loop through each BedroomUnits type and create a graph
for(bedroom in unique_bedroom_units) {
  # Filter data for the specific Bedroom Unit
  sub_data <- subset(all_data_sf, BedroomUnits == bedroom)
  
  # Generate the graph
  rent_graph <- ggplot(data = sub_data) +
    geom_sf(aes(fill = Rent), color = "white") +
    scale_fill_viridis_c(option = "C") +
    theme_minimal() +
    labs(title = paste("Rent Tertile Distribution in Clark County -", bedroom))
  
  # Store the graph in the list
  rent_graphs[[bedroom]] <- rent_graph
}

rent_graphs[["Efficiency"]]
# Display the graph for "1 Bedroom" units
rent_graphs[["One-Bedroom"]]
# Display the graph for "2 Bedroom" units
rent_graphs[["Two-Bedroom"]]
# Display the graph for "3 Bedroom" units
rent_graphs[["Three-Bedroom"]]
# Display the graph for "4 Bedroom" units
rent_graphs[["Four-Bedroom"]]


# Income
ggplot(data = all_data_sf) +
  geom_sf(aes(fill = income_tertile), color = "white") +
  scale_fill_viridis_c(option = "C") +
  theme_minimal() +
  labs(title = "Income Tertile Distribution in Clark County")

# BIPOC
ggplot(data = all_data_sf) +
  geom_sf(aes(fill = BIPOC_tertile), color = "white") +
  scale_fill_viridis_c(option = "C") +
  theme_minimal() +
  labs(title = "BIPOC Tertile Distribution in Clark County")

ggplot(data = all_data_sf) +
  geom_sf(aes(fill = SNAP_tertile), color = "white") +
  scale_fill_viridis_c(option = "C") +
  theme_minimal() +
  labs(title = "SNAP Tertile Distribution in Clark County")

```










To aid in analysis I decided to categorize my zip code data into tertile, except for rent. The values have been categorized as High, Medium, and Low.

The results from the Moran's I test applied to various tertile categories within my spatial autocorrelation study yield the following conclusions. The analysis of income tertiles revealed a positive Moran's I value coupled with a statistically significant p-value, indicating a pronounced clustering of similar income levels within the geographical confines of the study area. This discovery is pertinent, as it confirms the proximity of areas with comparable income brackets. Similarly, the BIPOC tertiles have demonstrated a robust positive Moran's I value alongside a negligible p-value, underscoring a significant spatial concentration of the BIPOC demographic. This observation aligns with the core interests of my research project. In the case of the SNAP tertiles, although the clustering pattern evidenced by the positive Moran's I value and its associated p-value is less striking than that of income and BIPOC categories, it remains a noteworthy aspect of the spatial pattern deserving of further consideration in the study.

The employment tertile data suggest a possible but not unequivocally confirmed clustering tendency, as reflected by a p-value on the threshold of significance. Further inquiry may be required to unravel the complexities of employment distribution more thoroughly. Conversely, the rent vacancy tertile data indicated an absence of significant spatial autocorrelation, given the elevated p-value. Therefore, rent vacancy rates might not exhibit distinct spatial trends within the scope of this research.

These findings guide the subsequent steps in my research, with an emphasis on the income and BIPOC tertiles that exhibit marked and statistically significant clustering. The SNAP tertile data will also receive due attention due to its analytical significance. 

I must acknowledge the challenges encountered while integrating linear regression techniques and clustering to this data. The complexity of the data structure and the intricacies of spatial analysis have posed a considerable learning curve. I understand this may not be the type of model you are expecting, but I hope it showcases my effort in working with this geospatial data. My goal is to implement clustering on zip codes to see the concentration of socio and economic challenges. 


# ---
Research question: How does the number of bedrooms in a unit influence the Fair Market Rent within Clark County, and how does this compare to the broader MSA data? Are federal housing affordability and assistance programs, which use MSA-level data, accurately reflecting the variance in housing costs within the diverse counties of the MSA, specifically Clark County? Does the model reveals that the number of bedrooms significantly impacts FMRs differently in Clark County compared to the rest of the MSA? 

Federal agencies using MSA to make County decisions. MSAs like Portland-Vancouver-Hillsboro are defined and used by HUD and other federal agencies for various purposes, including data collection, program administration, and policy planning in housing and urban development. Clark County, WA is part of the Portland-Vancouver-Hillsboro, OR-WA Metropolitan Statistical Area (MSA), which consists of the following counties: Clackamas County, OR; Columbia County, OR; Multnomah County, OR; Washington County, OR; Yamhill County, OR; Clark County, WA; and Skamania County, WA.

Given that Clark County is part of a larger Metropolitan Statistical Area (MSA) that includes counties from different states, could the use of aggregate MSA data to calculate Fair Market Rents (FMRs) for Clark County be problematic? Specifically, could differences in state tax policies, population density, land size, and other regional characteristics between Clark County and the other counties within the MSA lead to inaccuracies or misrepresentations in the FMRs calculated for Clark County?

Now for Clark, the analysis is as follows. We are able to reject the null hypothesis. The Multiple R-squared has improved to 0.5688, meaning the model now explains approximately 56.88% of the variance in FMRs, which is a slight increase from the previous model (MSA).
The Adjusted R-squared also increased to 0.5423, indicating a better fit after adjusting for the number of predictors. The residuals' spread is slightly smaller, with a Residual standard error of 433.5 compared to 442.1 in the previous model, indicating a marginally better fit.

I will say, after looking at my diagnostic plots, I may need to reconsider how I set up my linear regression model. Based on the plots, my model seems to meet some of the assumptions well, such as having no influential outliers. However, there is a hint of non-constant variance (heteroscedasticity), and the residuals might not be perfectly normally distributed (based on the Q-Q plot).

The output from your linear regression model with interaction terms indicates how the effect of bedroom size on Fair Market Rents (FMRs) might differ between Clark County and the Portland-Vancouver-Hillsboro MSA. We fail to reject the null hypothesis, interaction terms between BedroomUnits and Statistical Area are not statistically significant (p-values are greater than 0.05), suggesting that the effect of bedroom size on FMRs is not significantly different between Clark County and the broader MSA. This means that the number of bedrooms impacts FMRs similarly in Clark County as it does in the rest of the MSA.
# ---

```{r Spatial Lag Model}

# Create neighbors and weights for the spatial lag model
neighbors <- poly2nb(all_data_sf)
weights <- nb2listw(neighbors, style = "W")


# Spatial Lag Model
slm_model <- lagsarlm(Rent ~ income_tertile + BIPOC_tertile + SNAP_tertile, 
                      data = all_data_sf, listw = weights)

# View the summary of the model
summary(slm_model)

```



I employed a Spatial Lag Model (SLM) to explore the relationship between various socio-economic factors and rent levels in Clark County. This approach was particularly pertinent to our course objectives, as it combined advanced spatial analysis techniques with a real-world issue in housing affordability—an interdisciplinary topic that intersects economics, urban planning, and social policy.

Income Tertile's Impact: My model showed that the income tertile (income_tertile) significantly influences the rent tertile (Rent), with a coefficient of 0.59230 (p-value = 0.04051).
Interpretation: This finding indicates that areas with higher incomes tend to have higher rents. This result is critical for understanding the dynamics of housing affordability and economic disparities within Clark County, suggesting a pattern where wealthier neighborhoods are likely to have more expensive housing.

BIPOC Tertile Trends: The BIPOC tertile (BIPOC_tertile) showed a positive but not statistically significant relationship with rent tertile (p-value = 0.17256).
Interpretation: There appears to be a trend where areas with higher BIPOC populations might have higher rent levels, but this relationship is not conclusive in my data. This aspect of my analysis underscores the complexities of demographic factors in housing markets.

SNAP Tertile Analysis: I found no significant relationship between SNAP tertiles (SNAP_tertile) and rent tertiles (p-value = 0.74817).
Interpretation: The absence of a significant relationship suggests that SNAP benefit distribution does not have a clear spatial correlation with rent levels in Clark County, based on the variables in my model.
Spatial Autocorrelation (Rho):

The spatial lag term (Rho) was not significant (p-value = 0.41558), indicating that rent levels in one area are not significantly influenced by those in neighboring areas.
Interpretation: This suggests that the spatial dynamics driving rent levels in Clark County might be more complex, or perhaps the key spatially dependent factors are not captured by the variables in my model.


Opportunities for Further Research: This analysis opens up possibilities for further exploration, such as including additional variables or trying different spatial models, which aligns with the iterative nature of data analysis—a key learning outcome in our course.





```{r - Multinomial Logistic Regression}

# Loading the necessary package
library(nnet)

# Multinomial logistic regression
# 'rent_category' is your dependent variable
# Include your independent variables in the formula
multinom_model <- multinom(Rent ~ income_tertile + BIPOC_tertile + SNAP_tertile, 
                           data = all_data_sf)

# View the summary of the model
summary(multinom_model)


```



I conducted a multinomial logistic regression to understand how different socio-economic factors influence rent categories in Clark County. 

Coefficients Interpretation: My model provides coefficients for the "Low" and "Medium" rent categories, relative to the reference category, likely "High" rent. For instance, the coefficient for income_tertile in the "Low" category is -2.3025. This implies that as income tertile increases, the likelihood of being in the "Low" rent category (as opposed to "High") decreases. The coefficients for BIPOC_tertile follow a similar negative trend, while those for SNAP_tertile are positive, indicating a higher likelihood of falling into these rent categories with increasing SNAP tertile values.

Model Convergence and Fit: My model successfully converged, indicating that the algorithm found a stable solution. The Residual Deviance and AIC values provided are instrumental in evaluating the model's fit. Though these values alone don't give a complete picture of model quality, they are useful benchmarks for comparison with other models.


Interpreting the Results: The negative relationship of income with the lower rent categories resonates with the typical urban economic patterns, where higher income areas are less likely to have lower rent levels. This finding is pivotal in understanding the dynamics of housing affordability in Clark County.

Statistical Significance: Although the standard errors are provided, I need to perform additional steps, like Wald tests, to assess the statistical significance of the coefficients fully.




```{r Wald tests}

# 'multinom_model' is your multinomial logistic regression model
# Extract the coefficients and the variance-covariance matrix
coef_matrix <- coef(multinom_model)
cov_matrix <- vcov(multinom_model)

# Perform Wald test for a specific coefficient
# Perform Wald test for the 'income_tertile' coefficient in the 'Low' category
wald.test(b = coef_matrix["Low", "income_tertile"], 
          Sigma = cov_matrix["Low:income_tertile", "Low:income_tertile"], 
          Terms = 1)


# Perform Wald test for the 'BIPOC_tertile' coefficient in the 'Medium' category
wald.test(b = coef_matrix["Medium", "BIPOC_tertile"], 
          Sigma = cov_matrix["Medium:BIPOC_tertile", "Medium:BIPOC_tertile"], 
          Terms = 1)


```








